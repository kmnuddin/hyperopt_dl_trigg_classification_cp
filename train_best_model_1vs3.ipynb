{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helper\n",
    "from neural_net import build_and_train\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Helper('topomaps_1vs3/train/combined', 'topomaps_1vs3/test/combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_space_model = h.load_best_hyperspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 70.0,\n",
       " 'conv_dropout_drop_proba': 0.2319040800996359,\n",
       " 'conv_hiddn_units_mult': 0.7004255447579512,\n",
       " 'conv_kernel_size': 3.0,\n",
       " 'conv_pool_res_start_idx': 2.0,\n",
       " 'epochs': 180.0,\n",
       " 'fc_dropout_drop_proba': 0.17590859742643258,\n",
       " 'fc_units_1_mult': 0.9697958299395057,\n",
       " 'first_conv': None,\n",
       " 'l2_weight_reg_mult': 3.3401336643592123,\n",
       " 'lr_rate_mult': 0.6582150163080535,\n",
       " 'nb_conv_pool_layers': 2,\n",
       " 'one_more_fc': 1.1848111467718283,\n",
       " 'optimizer': 'Adam',\n",
       " 'pooling_type': 'inception',\n",
       " 'res_conv_kernel_size': 3.0,\n",
       " 'residual': None,\n",
       " 'use_BN': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_space_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Hyperspace:\n",
      "{'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}\n",
      "0\n",
      "28\n",
      "(None, 128, 128, 3)\n",
      "(None, 128, 128, 28)\n",
      "(None, 64, 64, 36)\n",
      "1\n",
      "56\n",
      "(None, 64, 64, 36)\n",
      "(None, 64, 64, 56)\n",
      "(None, 32, 32, 69)\n",
      "(None, 70656)\n",
      "(None, 969)\n",
      "(None, 888)\n",
      "Model's weights will be saved to: weights/940a3.hdf5\n",
      "Tensorboard log files will be saved to: TensorBoard/940a3\n",
      "Epoch 1/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 7.0807 - accuracy: 0.5009 - val_loss: 6.1666 - val_accuracy: 0.4989\n",
      "Epoch 2/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 5.4045 - accuracy: 0.4999 - val_loss: 4.7245 - val_accuracy: 0.4991\n",
      "Epoch 3/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 4.1972 - accuracy: 0.5035 - val_loss: 3.7314 - val_accuracy: 0.5097\n",
      "Epoch 4/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 3.3691 - accuracy: 0.5056 - val_loss: 3.0463 - val_accuracy: 0.5004\n",
      "Epoch 5/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 2.7874 - accuracy: 0.5088 - val_loss: 2.5510 - val_accuracy: 0.5215\n",
      "Epoch 6/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 2.3657 - accuracy: 0.5038 - val_loss: 2.1951 - val_accuracy: 0.5027\n",
      "Epoch 7/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 2.0599 - accuracy: 0.5033 - val_loss: 1.9335 - val_accuracy: 0.4989\n",
      "Epoch 8/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 1.8216 - accuracy: 0.5003 - val_loss: 1.7158 - val_accuracy: 0.4989\n",
      "Epoch 9/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 1.6254 - accuracy: 0.5023 - val_loss: 1.5395 - val_accuracy: 0.5009\n",
      "Epoch 10/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 1.4636 - accuracy: 0.5031 - val_loss: 1.3912 - val_accuracy: 0.5053\n",
      "Epoch 11/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 1.3309 - accuracy: 0.5079 - val_loss: 1.2761 - val_accuracy: 0.5016\n",
      "Epoch 12/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 1.2333 - accuracy: 0.5072 - val_loss: 1.1939 - val_accuracy: 0.5117\n",
      "Epoch 13/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 1.1599 - accuracy: 0.5170 - val_loss: 1.1274 - val_accuracy: 0.5399\n",
      "Epoch 14/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 1.0985 - accuracy: 0.5379 - val_loss: 1.0667 - val_accuracy: 0.5606\n",
      "Epoch 15/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 1.0507 - accuracy: 0.5573 - val_loss: 1.0280 - val_accuracy: 0.5743\n",
      "Epoch 16/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 1.0162 - accuracy: 0.5713 - val_loss: 1.0101 - val_accuracy: 0.5717\n",
      "Epoch 17/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 0.9877 - accuracy: 0.5885 - val_loss: 0.9714 - val_accuracy: 0.6022\n",
      "Epoch 18/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.9644 - accuracy: 0.6043 - val_loss: 0.9561 - val_accuracy: 0.6274\n",
      "Epoch 19/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 0.9372 - accuracy: 0.6397 - val_loss: 0.9088 - val_accuracy: 0.6756\n",
      "Epoch 20/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.9051 - accuracy: 0.6732 - val_loss: 0.8845 - val_accuracy: 0.6880\n",
      "Epoch 21/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 0.8776 - accuracy: 0.6961 - val_loss: 0.8691 - val_accuracy: 0.6982\n",
      "Epoch 22/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.8513 - accuracy: 0.7146 - val_loss: 0.8375 - val_accuracy: 0.7265\n",
      "Epoch 23/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.8266 - accuracy: 0.7335 - val_loss: 0.8398 - val_accuracy: 0.7210\n",
      "Epoch 24/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.8056 - accuracy: 0.7477 - val_loss: 0.8005 - val_accuracy: 0.7553\n",
      "Epoch 25/180\n",
      "572/572 [==============================] - 151s 263ms/step - loss: 0.7863 - accuracy: 0.7575 - val_loss: 0.7890 - val_accuracy: 0.7558\n",
      "Epoch 26/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 0.7663 - accuracy: 0.7699 - val_loss: 0.7752 - val_accuracy: 0.7667\n",
      "Epoch 27/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.7492 - accuracy: 0.7819 - val_loss: 0.7887 - val_accuracy: 0.7593\n",
      "Epoch 28/180\n",
      "572/572 [==============================] - 148s 260ms/step - loss: 0.7313 - accuracy: 0.7907 - val_loss: 0.7527 - val_accuracy: 0.7787\n",
      "Epoch 29/180\n",
      "572/572 [==============================] - 152s 265ms/step - loss: 0.7141 - accuracy: 0.8006 - val_loss: 0.7455 - val_accuracy: 0.7835\n",
      "Epoch 30/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.7026 - accuracy: 0.8068 - val_loss: 0.7360 - val_accuracy: 0.7910\n",
      "Epoch 31/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.6853 - accuracy: 0.8157 - val_loss: 0.7220 - val_accuracy: 0.7948\n",
      "Epoch 32/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.6752 - accuracy: 0.8215 - val_loss: 0.7170 - val_accuracy: 0.7980\n",
      "Epoch 33/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.6600 - accuracy: 0.8279 - val_loss: 0.7200 - val_accuracy: 0.7982\n",
      "Epoch 34/180\n",
      "572/572 [==============================] - 149s 260ms/step - loss: 0.6521 - accuracy: 0.8317 - val_loss: 0.7139 - val_accuracy: 0.7994\n",
      "Epoch 35/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.6392 - accuracy: 0.8382 - val_loss: 0.7020 - val_accuracy: 0.8056\n",
      "Epoch 36/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.6275 - accuracy: 0.8437 - val_loss: 0.7064 - val_accuracy: 0.8075\n",
      "Epoch 37/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.6147 - accuracy: 0.8533 - val_loss: 0.6940 - val_accuracy: 0.8053\n",
      "Epoch 38/180\n",
      "572/572 [==============================] - 149s 260ms/step - loss: 0.6055 - accuracy: 0.8562 - val_loss: 0.6955 - val_accuracy: 0.8090\n",
      "Epoch 39/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.5931 - accuracy: 0.8626 - val_loss: 0.6822 - val_accuracy: 0.8172\n",
      "Epoch 40/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.5828 - accuracy: 0.8672 - val_loss: 0.6991 - val_accuracy: 0.8112\n",
      "Epoch 41/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.5743 - accuracy: 0.8712 - val_loss: 0.7132 - val_accuracy: 0.8069\n",
      "Epoch 42/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.5635 - accuracy: 0.8758 - val_loss: 0.6855 - val_accuracy: 0.8159\n",
      "Epoch 43/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.5540 - accuracy: 0.8791 - val_loss: 0.6867 - val_accuracy: 0.8166\n",
      "Epoch 44/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.5465 - accuracy: 0.8839 - val_loss: 0.6666 - val_accuracy: 0.8225\n",
      "Epoch 45/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.5361 - accuracy: 0.8899 - val_loss: 0.6741 - val_accuracy: 0.8209\n",
      "Epoch 46/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 0.5261 - accuracy: 0.8918 - val_loss: 0.6834 - val_accuracy: 0.8179\n",
      "Epoch 47/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.5173 - accuracy: 0.8971 - val_loss: 0.7048 - val_accuracy: 0.8108\n",
      "Epoch 48/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.5103 - accuracy: 0.8997 - val_loss: 0.6638 - val_accuracy: 0.8290\n",
      "Epoch 49/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.5021 - accuracy: 0.9031 - val_loss: 0.6897 - val_accuracy: 0.8226\n",
      "Epoch 50/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 149s 260ms/step - loss: 0.4943 - accuracy: 0.9076 - val_loss: 0.6728 - val_accuracy: 0.8307\n",
      "Epoch 51/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.4865 - accuracy: 0.9094 - val_loss: 0.6710 - val_accuracy: 0.8299\n",
      "Epoch 52/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.4803 - accuracy: 0.9129 - val_loss: 0.6714 - val_accuracy: 0.8300\n",
      "Epoch 53/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.4712 - accuracy: 0.9176 - val_loss: 0.6750 - val_accuracy: 0.8297\n",
      "Epoch 54/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.4640 - accuracy: 0.9197 - val_loss: 0.6832 - val_accuracy: 0.8271\n",
      "Epoch 55/180\n",
      "572/572 [==============================] - 151s 265ms/step - loss: 0.4624 - accuracy: 0.9216 - val_loss: 0.6677 - val_accuracy: 0.8347\n",
      "Epoch 56/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.4515 - accuracy: 0.9257 - val_loss: 0.6804 - val_accuracy: 0.8310\n",
      "Epoch 57/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4461 - accuracy: 0.9273 - val_loss: 0.6714 - val_accuracy: 0.8336\n",
      "Epoch 58/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.4407 - accuracy: 0.9297 - val_loss: 0.7015 - val_accuracy: 0.8265\n",
      "Epoch 59/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.4319 - accuracy: 0.9347 - val_loss: 0.6969 - val_accuracy: 0.8291\n",
      "Epoch 60/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.4275 - accuracy: 0.9353 - val_loss: 0.6744 - val_accuracy: 0.8358\n",
      "Epoch 61/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4207 - accuracy: 0.9384 - val_loss: 0.7163 - val_accuracy: 0.8253\n",
      "Epoch 62/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4189 - accuracy: 0.9393 - val_loss: 0.6886 - val_accuracy: 0.8365\n",
      "Epoch 63/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4118 - accuracy: 0.9412 - val_loss: 0.7078 - val_accuracy: 0.8292\n",
      "Epoch 64/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.4075 - accuracy: 0.9427 - val_loss: 0.6787 - val_accuracy: 0.8360\n",
      "Epoch 65/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4013 - accuracy: 0.9449 - val_loss: 0.6908 - val_accuracy: 0.8358\n",
      "Epoch 66/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.3966 - accuracy: 0.9474 - val_loss: 0.6877 - val_accuracy: 0.8376\n",
      "Epoch 67/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3923 - accuracy: 0.9484 - val_loss: 0.6994 - val_accuracy: 0.8356\n",
      "Epoch 68/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3849 - accuracy: 0.9527 - val_loss: 0.6855 - val_accuracy: 0.8370\n",
      "Epoch 69/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3827 - accuracy: 0.9525 - val_loss: 0.6989 - val_accuracy: 0.8324\n",
      "Epoch 70/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 0.3767 - accuracy: 0.9547 - val_loss: 0.7057 - val_accuracy: 0.8358\n",
      "Epoch 71/180\n",
      "572/572 [==============================] - 139s 244ms/step - loss: 0.3771 - accuracy: 0.9541 - val_loss: 0.7015 - val_accuracy: 0.8351\n",
      "Epoch 72/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3708 - accuracy: 0.9559 - val_loss: 0.7606 - val_accuracy: 0.8220\n",
      "Epoch 73/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3691 - accuracy: 0.9578 - val_loss: 0.7193 - val_accuracy: 0.8341\n",
      "Epoch 74/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.3634 - accuracy: 0.9595 - val_loss: 0.7133 - val_accuracy: 0.8343\n",
      "Epoch 75/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3613 - accuracy: 0.9593 - val_loss: 0.6982 - val_accuracy: 0.8430\n",
      "Epoch 76/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3560 - accuracy: 0.9607 - val_loss: 0.7044 - val_accuracy: 0.8409\n",
      "Epoch 77/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3537 - accuracy: 0.9634 - val_loss: 0.7200 - val_accuracy: 0.8373\n",
      "Epoch 78/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3494 - accuracy: 0.9651 - val_loss: 0.7093 - val_accuracy: 0.8403\n",
      "Epoch 79/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3470 - accuracy: 0.9642 - val_loss: 0.7293 - val_accuracy: 0.8377\n",
      "Epoch 80/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3431 - accuracy: 0.9664 - val_loss: 0.7178 - val_accuracy: 0.8369\n",
      "Epoch 81/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3417 - accuracy: 0.9675 - val_loss: 0.7125 - val_accuracy: 0.8412\n",
      "Epoch 82/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 0.3373 - accuracy: 0.9681 - val_loss: 0.7267 - val_accuracy: 0.8391\n",
      "Epoch 83/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3360 - accuracy: 0.9675 - val_loss: 0.7674 - val_accuracy: 0.8317\n",
      "Epoch 84/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3337 - accuracy: 0.9695 - val_loss: 0.7277 - val_accuracy: 0.8374\n",
      "Epoch 85/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3300 - accuracy: 0.9710 - val_loss: 0.7292 - val_accuracy: 0.8435\n",
      "Epoch 86/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3269 - accuracy: 0.9714 - val_loss: 0.7378 - val_accuracy: 0.8400\n",
      "Epoch 87/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3286 - accuracy: 0.9707 - val_loss: 0.7213 - val_accuracy: 0.8421\n",
      "Epoch 88/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3234 - accuracy: 0.9726 - val_loss: 0.7242 - val_accuracy: 0.8400\n",
      "Epoch 89/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3186 - accuracy: 0.9741 - val_loss: 0.7493 - val_accuracy: 0.8377\n",
      "Epoch 90/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3194 - accuracy: 0.9725 - val_loss: 0.7289 - val_accuracy: 0.8408\n",
      "Epoch 91/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3152 - accuracy: 0.9752 - val_loss: 0.7421 - val_accuracy: 0.8392\n",
      "Epoch 92/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3102 - accuracy: 0.9768 - val_loss: 0.7368 - val_accuracy: 0.8423\n",
      "Epoch 93/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3110 - accuracy: 0.9758 - val_loss: 0.7318 - val_accuracy: 0.8467\n",
      "Epoch 94/180\n",
      "572/572 [==============================] - 136s 238ms/step - loss: 0.3069 - accuracy: 0.9775 - val_loss: 0.7390 - val_accuracy: 0.8390\n",
      "Epoch 95/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3075 - accuracy: 0.9769 - val_loss: 0.7320 - val_accuracy: 0.8438\n",
      "Epoch 96/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3053 - accuracy: 0.9776 - val_loss: 0.7343 - val_accuracy: 0.8396\n",
      "Epoch 97/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3017 - accuracy: 0.9796 - val_loss: 0.7464 - val_accuracy: 0.8412\n",
      "Epoch 98/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.3019 - accuracy: 0.9795 - val_loss: 0.7487 - val_accuracy: 0.8420\n",
      "Epoch 99/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.2977 - accuracy: 0.9812 - val_loss: 0.7448 - val_accuracy: 0.8426\n",
      "Epoch 100/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2967 - accuracy: 0.9803 - val_loss: 0.7332 - val_accuracy: 0.8438\n",
      "Epoch 101/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2950 - accuracy: 0.9803 - val_loss: 0.7409 - val_accuracy: 0.8414\n",
      "Epoch 102/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2930 - accuracy: 0.9814 - val_loss: 0.7773 - val_accuracy: 0.8379\n",
      "Epoch 103/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2924 - accuracy: 0.9809 - val_loss: 0.7656 - val_accuracy: 0.8404\n",
      "Epoch 104/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2897 - accuracy: 0.9822 - val_loss: 0.7597 - val_accuracy: 0.8389\n",
      "Epoch 105/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2881 - accuracy: 0.9828 - val_loss: 0.7626 - val_accuracy: 0.8403\n",
      "Epoch 106/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2846 - accuracy: 0.9832 - val_loss: 0.7463 - val_accuracy: 0.8428\n",
      "Epoch 107/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2836 - accuracy: 0.9838 - val_loss: 0.7622 - val_accuracy: 0.8411\n",
      "Epoch 108/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2868 - accuracy: 0.9814 - val_loss: 0.7482 - val_accuracy: 0.8414\n",
      "Epoch 109/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2830 - accuracy: 0.9836 - val_loss: 0.7574 - val_accuracy: 0.8413\n",
      "Epoch 110/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2813 - accuracy: 0.9833 - val_loss: 0.7452 - val_accuracy: 0.8442\n",
      "Epoch 111/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2803 - accuracy: 0.9836 - val_loss: 0.7419 - val_accuracy: 0.8429\n",
      "Epoch 112/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2791 - accuracy: 0.9841 - val_loss: 0.7532 - val_accuracy: 0.8448\n",
      "Epoch 113/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2776 - accuracy: 0.9841 - val_loss: 0.7437 - val_accuracy: 0.8408\n",
      "Epoch 114/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2753 - accuracy: 0.9850 - val_loss: 0.7438 - val_accuracy: 0.8432\n",
      "Epoch 115/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2733 - accuracy: 0.9859 - val_loss: 0.7475 - val_accuracy: 0.8443\n",
      "Epoch 116/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2733 - accuracy: 0.9857 - val_loss: 0.7582 - val_accuracy: 0.8390\n",
      "Epoch 117/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2710 - accuracy: 0.9863 - val_loss: 0.7462 - val_accuracy: 0.8434\n",
      "Epoch 118/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2701 - accuracy: 0.9866 - val_loss: 0.7627 - val_accuracy: 0.8373\n",
      "Epoch 119/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2680 - accuracy: 0.9871 - val_loss: 0.7591 - val_accuracy: 0.8420\n",
      "Epoch 120/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2669 - accuracy: 0.9872 - val_loss: 0.7666 - val_accuracy: 0.8409\n",
      "Epoch 121/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2660 - accuracy: 0.9870 - val_loss: 0.7614 - val_accuracy: 0.8438\n",
      "Epoch 122/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2661 - accuracy: 0.9864 - val_loss: 0.7654 - val_accuracy: 0.8416\n",
      "Epoch 123/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2622 - accuracy: 0.9880 - val_loss: 0.7487 - val_accuracy: 0.8437\n",
      "Epoch 124/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2632 - accuracy: 0.9872 - val_loss: 0.7382 - val_accuracy: 0.8424\n",
      "Epoch 125/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2623 - accuracy: 0.9869 - val_loss: 0.7727 - val_accuracy: 0.8365\n",
      "Epoch 126/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2613 - accuracy: 0.9872 - val_loss: 0.7682 - val_accuracy: 0.8374\n",
      "Epoch 127/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2596 - accuracy: 0.9886 - val_loss: 0.7764 - val_accuracy: 0.8382\n",
      "Epoch 128/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2582 - accuracy: 0.9881 - val_loss: 0.7650 - val_accuracy: 0.8376\n",
      "Epoch 129/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2553 - accuracy: 0.9900 - val_loss: 0.7442 - val_accuracy: 0.8452\n",
      "Epoch 130/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2575 - accuracy: 0.9878 - val_loss: 0.7764 - val_accuracy: 0.8382\n",
      "Epoch 131/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2553 - accuracy: 0.9884 - val_loss: 0.7886 - val_accuracy: 0.8366\n",
      "Epoch 132/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2537 - accuracy: 0.9891 - val_loss: 0.7861 - val_accuracy: 0.8342\n",
      "Epoch 133/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2521 - accuracy: 0.9897 - val_loss: 0.7438 - val_accuracy: 0.8445\n",
      "Epoch 134/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2530 - accuracy: 0.9890 - val_loss: 0.7464 - val_accuracy: 0.8401\n",
      "Epoch 135/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2528 - accuracy: 0.9880 - val_loss: 0.7600 - val_accuracy: 0.8410\n",
      "Epoch 136/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2482 - accuracy: 0.9902 - val_loss: 0.7490 - val_accuracy: 0.8412\n",
      "Epoch 137/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2483 - accuracy: 0.9898 - val_loss: 0.7501 - val_accuracy: 0.8432\n",
      "Epoch 138/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2473 - accuracy: 0.9901 - val_loss: 0.7668 - val_accuracy: 0.8417\n",
      "Epoch 139/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2471 - accuracy: 0.9900 - val_loss: 0.7350 - val_accuracy: 0.8461\n",
      "Epoch 140/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2472 - accuracy: 0.9898 - val_loss: 0.7478 - val_accuracy: 0.8401\n",
      "Epoch 141/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2438 - accuracy: 0.9913 - val_loss: 0.7520 - val_accuracy: 0.8402\n",
      "Epoch 142/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2429 - accuracy: 0.9912 - val_loss: 0.7659 - val_accuracy: 0.8389\n",
      "Epoch 143/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2412 - accuracy: 0.9908 - val_loss: 0.7738 - val_accuracy: 0.8401\n",
      "Epoch 144/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2425 - accuracy: 0.9902 - val_loss: 0.7639 - val_accuracy: 0.8366\n",
      "Epoch 145/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2404 - accuracy: 0.9906 - val_loss: 0.7451 - val_accuracy: 0.8419\n",
      "Epoch 146/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2378 - accuracy: 0.9922 - val_loss: 0.7476 - val_accuracy: 0.8414\n",
      "Epoch 147/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2387 - accuracy: 0.9911 - val_loss: 0.7403 - val_accuracy: 0.8439\n",
      "Epoch 148/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2371 - accuracy: 0.9915 - val_loss: 0.7579 - val_accuracy: 0.8400\n",
      "Epoch 149/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2361 - accuracy: 0.9916 - val_loss: 0.7566 - val_accuracy: 0.8384\n",
      "Epoch 150/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2358 - accuracy: 0.9918 - val_loss: 0.8235 - val_accuracy: 0.8297\n",
      "Epoch 151/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2372 - accuracy: 0.9905 - val_loss: 0.7579 - val_accuracy: 0.8401\n",
      "Epoch 152/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2340 - accuracy: 0.9920 - val_loss: 0.7357 - val_accuracy: 0.8445\n",
      "Epoch 153/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2322 - accuracy: 0.9923 - val_loss: 0.7469 - val_accuracy: 0.8406\n",
      "Epoch 154/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2338 - accuracy: 0.9913 - val_loss: 0.7317 - val_accuracy: 0.8432\n",
      "Epoch 155/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2319 - accuracy: 0.9919 - val_loss: 0.7257 - val_accuracy: 0.8442\n",
      "Epoch 156/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2309 - accuracy: 0.9919 - val_loss: 0.7254 - val_accuracy: 0.8458\n",
      "Epoch 157/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2314 - accuracy: 0.9916 - val_loss: 0.7304 - val_accuracy: 0.8442\n",
      "Epoch 158/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2290 - accuracy: 0.9924 - val_loss: 0.7395 - val_accuracy: 0.8428\n",
      "Epoch 159/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2286 - accuracy: 0.9921 - val_loss: 0.7260 - val_accuracy: 0.8432\n",
      "Epoch 160/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2290 - accuracy: 0.9918 - val_loss: 0.7351 - val_accuracy: 0.8418\n",
      "Epoch 161/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2274 - accuracy: 0.9922 - val_loss: 0.7562 - val_accuracy: 0.8404\n",
      "Epoch 162/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2257 - accuracy: 0.9925 - val_loss: 0.7339 - val_accuracy: 0.8461\n",
      "Epoch 163/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2248 - accuracy: 0.9925 - val_loss: 0.7622 - val_accuracy: 0.8359\n",
      "Epoch 164/180\n",
      "572/572 [==============================] - 138s 240ms/step - loss: 0.2233 - accuracy: 0.9932 - val_loss: 0.7250 - val_accuracy: 0.8407\n",
      "Epoch 165/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2223 - accuracy: 0.9932 - val_loss: 0.7297 - val_accuracy: 0.8429\n",
      "Epoch 166/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2229 - accuracy: 0.9923 - val_loss: 0.7268 - val_accuracy: 0.8469\n",
      "Epoch 167/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2225 - accuracy: 0.9931 - val_loss: 0.7170 - val_accuracy: 0.8436\n",
      "Epoch 168/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2214 - accuracy: 0.9928 - val_loss: 0.7105 - val_accuracy: 0.8494\n",
      "Epoch 169/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2207 - accuracy: 0.9930 - val_loss: 0.7269 - val_accuracy: 0.8425\n",
      "Epoch 170/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2199 - accuracy: 0.9930 - val_loss: 0.7294 - val_accuracy: 0.8445\n",
      "Epoch 171/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2199 - accuracy: 0.9925 - val_loss: 0.7317 - val_accuracy: 0.8419\n",
      "Epoch 172/180\n",
      "572/572 [==============================] - 137s 240ms/step - loss: 0.2181 - accuracy: 0.9931 - val_loss: 0.7351 - val_accuracy: 0.8412\n",
      "Epoch 173/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2181 - accuracy: 0.9931 - val_loss: 0.7330 - val_accuracy: 0.8415\n",
      "Epoch 174/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2172 - accuracy: 0.9925 - val_loss: 0.7286 - val_accuracy: 0.8437\n",
      "Epoch 175/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2160 - accuracy: 0.9934 - val_loss: 0.7256 - val_accuracy: 0.8431\n",
      "Epoch 176/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2152 - accuracy: 0.9934 - val_loss: 0.7117 - val_accuracy: 0.8460\n",
      "Epoch 177/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2158 - accuracy: 0.9927 - val_loss: 0.7167 - val_accuracy: 0.8439\n",
      "Epoch 178/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2138 - accuracy: 0.9936 - val_loss: 0.7233 - val_accuracy: 0.8452\n",
      "Epoch 179/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2135 - accuracy: 0.9931 - val_loss: 0.7535 - val_accuracy: 0.8354\n",
      "Epoch 180/180\n",
      "572/572 [==============================] - 138s 241ms/step - loss: 0.2136 - accuracy: 0.9931 - val_loss: 0.7235 - val_accuracy: 0.8423\n",
      "Model name: model_0.8494_0c7c0\n",
      "0.8494\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "{'loss': [7.081202768564224, 5.404600549459458, 4.1975427120924, 3.3689874928593637, 2.7875776264071463, 2.365519870042801, 2.059789636850357, 1.8215507144927978, 1.6254139703214168, 1.463521480858326, 1.3308424411416053, 1.2333458765745162, 1.159877765983343, 1.0985746369063853, 1.0506940851956605, 1.01626694637537, 0.9877620755285025, 0.9644491251707077, 0.9372542420476675, 0.9052062191665172, 0.8775375117659568, 0.8513475795686245, 0.8267054877877236, 0.8056542559415102, 0.7863045273274183, 0.7663602123558522, 0.749229172989726, 0.7313024708181619, 0.7142907594442367, 0.7026050241738557, 0.6854768459796905, 0.6751296905726194, 0.6600485518947243, 0.6521570508033038, 0.6392926322817802, 0.6273390235155821, 0.6146865681782365, 0.6055884653553366, 0.5933213873207569, 0.5827652420178056, 0.5742434389293194, 0.5634437347725034, 0.5538858204782009, 0.546558718316257, 0.5359912832304835, 0.526170092150569, 0.5172752892673016, 0.5103385574966669, 0.5021617424637079, 0.49434797900170085, 0.4865756802931428, 0.4802488168925047, 0.47117189870774745, 0.46401650781929493, 0.4624159524142742, 0.4514208651930094, 0.44614965307712556, 0.4407708392292261, 0.4319781200140715, 0.42756105913221837, 0.420753588616848, 0.4190040235221386, 0.4118428230881691, 0.4076050059720874, 0.4013362550958991, 0.39661726535111663, 0.3923003472313285, 0.3848209879249334, 0.38272674345970153, 0.37671725945174694, 0.3771741530224681, 0.37079364639520646, 0.3689665643721819, 0.36341783904284236, 0.361214303933084, 0.35605406525731087, 0.3536871397048235, 0.3494204364940524, 0.3470575150847435, 0.3431140293627977, 0.3416964449360967, 0.3373395440131426, 0.33590914838016034, 0.333648488022387, 0.3299262988939881, 0.32688938252627847, 0.32859997530281543, 0.32324834290891885, 0.3186374520584941, 0.31944627963006494, 0.3151688088402152, 0.31024615608155726, 0.311096448905766, 0.30693582282960413, 0.30747969663888214, 0.30529557006061075, 0.3016904081106186, 0.3019075457006693, 0.29766697783768176, 0.29669223485141993, 0.294920125965029, 0.2930342521443963, 0.29238119725883005, 0.28973894379287957, 0.28807148106768726, 0.28463599281385543, 0.2835832518711686, 0.28687421499192717, 0.28301353995874523, 0.28131752856820824, 0.2803311654254794, 0.27901993694901467, 0.27761042023822663, 0.27520724819228054, 0.273369573071599, 0.2732470675371587, 0.27097316447645425, 0.270141052775085, 0.26805619080364707, 0.26695298558473585, 0.2660002869516611, 0.2661661446839571, 0.2622068486474454, 0.26321691935509445, 0.26229744889959694, 0.2612752495110035, 0.2595714011453092, 0.25819899014383557, 0.25521450316533445, 0.2575166441611946, 0.25533744239807127, 0.2536708165332675, 0.2520659342184663, 0.25301347966864707, 0.2527885477617383, 0.2481921663247049, 0.2483472350426018, 0.24733469916135073, 0.2470950925387442, 0.24713288059085609, 0.24379521163925527, 0.2429333002269268, 0.24121404414251446, 0.24243951234966515, 0.24036095670238136, 0.23777556524798274, 0.23874889117851852, 0.2371039930768311, 0.2361368903554976, 0.23576739310845732, 0.2372535712532699, 0.23395329642668367, 0.23225812421366573, 0.23378038147464394, 0.23186320426315069, 0.23089745009317994, 0.23139147689938544, 0.2289699429795146, 0.22866029197722673, 0.22903119036182762, 0.22731273087486625, 0.2256982461810112, 0.22486673599854112, 0.22323830211907625, 0.22233963980153204, 0.22293473021686078, 0.22252986899390817, 0.22136048175394535, 0.2206760775707662, 0.21989216267690062, 0.21990911710634828, 0.2181233935393393, 0.21807453898712992, 0.21721778643131257, 0.21603274131566286, 0.215260263197124, 0.21567704283446074, 0.21386426182836293, 0.21346258627995848, 0.21366150326281785], 'accuracy': [0.5009, 0.4999, 0.50355, 0.5056, 0.508775, 0.5038, 0.503275, 0.50035, 0.502275, 0.5031, 0.5079, 0.507175, 0.516975, 0.53795, 0.557325, 0.57135, 0.58855, 0.604275, 0.6397, 0.67315, 0.6961, 0.71455, 0.733525, 0.747675, 0.757525, 0.7699, 0.7819, 0.79065, 0.800625, 0.806825, 0.8157, 0.821475, 0.8279, 0.83165, 0.83815, 0.843675, 0.8533, 0.856225, 0.862625, 0.867175, 0.87125, 0.8758, 0.879075, 0.88395, 0.889925, 0.89185, 0.89715, 0.89975, 0.903075, 0.907625, 0.9094, 0.912875, 0.917575, 0.91965, 0.921575, 0.925725, 0.92735, 0.929725, 0.93465, 0.9353, 0.938375, 0.939275, 0.941175, 0.942675, 0.94495, 0.9474, 0.948375, 0.952675, 0.952525, 0.9547, 0.95405, 0.95585, 0.95775, 0.95945, 0.959325, 0.96075, 0.963425, 0.96515, 0.964225, 0.966375, 0.9675, 0.96805, 0.96755, 0.969475, 0.971025, 0.9714, 0.9707, 0.97265, 0.974125, 0.972525, 0.975225, 0.9768, 0.97585, 0.977525, 0.97695, 0.97765, 0.9796, 0.9795, 0.9812, 0.980325, 0.9803, 0.98135, 0.9809, 0.98215, 0.982825, 0.9832, 0.983825, 0.981425, 0.983625, 0.98335, 0.9836, 0.98415, 0.9841, 0.984975, 0.98595, 0.9857, 0.986275, 0.9866, 0.9871, 0.98715, 0.986975, 0.9864, 0.98805, 0.98715, 0.98695, 0.98715, 0.9886, 0.988125, 0.989975, 0.9878, 0.988375, 0.9891, 0.98965, 0.98905, 0.98795, 0.990225, 0.98975, 0.9901, 0.989975, 0.98975, 0.991275, 0.99125, 0.990825, 0.990175, 0.9906, 0.99215, 0.99105, 0.991525, 0.991625, 0.99175, 0.99055, 0.992, 0.992275, 0.991325, 0.99195, 0.991875, 0.99155, 0.99245, 0.992075, 0.99175, 0.99215, 0.992475, 0.992475, 0.993225, 0.993175, 0.992325, 0.993075, 0.992825, 0.99295, 0.993, 0.992525, 0.99315, 0.993125, 0.9925, 0.993425, 0.993425, 0.9927, 0.993625, 0.99315, 0.9931], 'val_loss': [6.166601234382683, 4.7245416074366, 3.7313923102158766, 3.046293923904846, 2.55097709168921, 2.195076563975194, 1.9334711561669837, 1.7157665274359963, 1.5395270952811608, 1.3911549578179847, 1.276118461902325, 1.1939269354293396, 1.1274435011656967, 1.0667308252174537, 1.0279998908509742, 1.0101483368373418, 0.9713755616774926, 0.9560564735552648, 0.9088454809222188, 0.8844563835984344, 0.8691216807265382, 0.8374980279615709, 0.8397676761333759, 0.8004526295861998, 0.7890197705555629, 0.7751504249506064, 0.7886512450404934, 0.7526605554393955, 0.7455285333253286, 0.7359692316788894, 0.7219964770170358, 0.7170419951418897, 0.7200409801273079, 0.7139182136609004, 0.7019961868132745, 0.706386573664792, 0.6940048991383373, 0.6955215193174936, 0.6822396304223921, 0.6990767588148584, 0.7132330070008764, 0.6855047997478005, 0.6867218640717593, 0.6666043984306442, 0.674098552523793, 0.683411876013229, 0.7047558201776518, 0.6637952419427725, 0.6897153329182338, 0.672819726533823, 0.6710133813061081, 0.6714101031526819, 0.6750098027132608, 0.6831777489685512, 0.6676529262449358, 0.6803663264621388, 0.6713521682715916, 0.7014835528977268, 0.6969100378610037, 0.6744453754875209, 0.7163160487071617, 0.6885571100495078, 0.707818563793089, 0.6786904853957516, 0.6908257136811743, 0.6877305968241259, 0.699361981628658, 0.6855022440423498, 0.6988606079891845, 0.7056650263029378, 0.7015302258354801, 0.7605898401120326, 0.7192754983068346, 0.7132800652847423, 0.6981671281627841, 0.7043805620470247, 0.7200056720863689, 0.7093437186904721, 0.7293132735299064, 0.7177601125273672, 0.7125054131021032, 0.7266586466685875, 0.767409695611967, 0.727730905050998, 0.7291513291689066, 0.7378011854378493, 0.7212569186320672, 0.724200968142156, 0.7493113975424867, 0.7288808303696293, 0.742094241447382, 0.7367537286314931, 0.7317832870916887, 0.7390202223420976, 0.73198022438096, 0.7342848667314836, 0.7463904579619428, 0.7487152885723781, 0.744776543828991, 0.733199985710891, 0.7408589533158949, 0.7772572444869088, 0.765618707958635, 0.7597012034246138, 0.7625541018022524, 0.7463411701309097, 0.7621966460784833, 0.7482084148413651, 0.7573897069567567, 0.7451880405416021, 0.741866191783985, 0.7532418459862262, 0.7436596974209472, 0.7437529922365309, 0.7475346158017645, 0.7582039195340831, 0.7462211263763321, 0.7626690389393093, 0.7590821935580327, 0.7666375805864801, 0.7614337962407333, 0.7653897838159041, 0.7486603722705708, 0.7382303499258481, 0.7726987373161983, 0.7682235930766259, 0.7763870627313227, 0.7650282866471297, 0.744159209144699, 0.7764414613480335, 0.7885523784410703, 0.786127077532815, 0.7437764752161252, 0.7463975477885533, 0.7600039589655149, 0.7489905484489627, 0.7501072083319817, 0.7667784094810486, 0.7349599606090492, 0.7477887112360734, 0.7520134876241217, 0.7658672634955053, 0.7738293957460177, 0.7639449274206495, 0.7451385507633635, 0.7475903363494606, 0.7403269653970544, 0.7578550960634138, 0.7565909719967342, 0.8235042397375707, 0.7578521525109565, 0.735653363949769, 0.7469262751665983, 0.7316799882825438, 0.7256843078803349, 0.725392756136981, 0.7303987537230645, 0.7394971893383906, 0.7260145051079196, 0.7351156141791311, 0.7561719273770606, 0.7339499805357073, 0.7621574295567466, 0.725034869842596, 0.7297453267590983, 0.7267785357845413, 0.7170004392420495, 0.7104610025465905, 0.7269397004917785, 0.7294003204865889, 0.731735281177334, 0.7350990021979058, 0.7329889571333265, 0.7285510328682986, 0.7255951797628736, 0.7117331561508712, 0.7166835961641965, 0.7232622556336277, 0.7534605139618987, 0.7235320825260002], 'val_accuracy': [0.4989, 0.4991, 0.5097, 0.5004, 0.5215, 0.5027, 0.4989, 0.4989, 0.5009, 0.5053, 0.5016, 0.5117, 0.5399, 0.5606, 0.5743, 0.5717, 0.6022, 0.6274, 0.6756, 0.688, 0.6982, 0.7265, 0.721, 0.7553, 0.7558, 0.7667, 0.7593, 0.7787, 0.7835, 0.791, 0.7948, 0.798, 0.7982, 0.7994, 0.8056, 0.8075, 0.8053, 0.809, 0.8172, 0.8112, 0.8069, 0.8159, 0.8166, 0.8225, 0.8209, 0.8179, 0.8108, 0.829, 0.8226, 0.8307, 0.8299, 0.83, 0.8297, 0.8271, 0.8347, 0.831, 0.8336, 0.8265, 0.8291, 0.8358, 0.8253, 0.8365, 0.8292, 0.836, 0.8358, 0.8376, 0.8356, 0.837, 0.8324, 0.8358, 0.8351, 0.822, 0.8341, 0.8343, 0.843, 0.8409, 0.8373, 0.8403, 0.8377, 0.8369, 0.8412, 0.8391, 0.8317, 0.8374, 0.8435, 0.84, 0.8421, 0.84, 0.8377, 0.8408, 0.8392, 0.8423, 0.8467, 0.839, 0.8438, 0.8396, 0.8412, 0.842, 0.8426, 0.8438, 0.8414, 0.8379, 0.8404, 0.8389, 0.8403, 0.8428, 0.8411, 0.8414, 0.8413, 0.8442, 0.8429, 0.8448, 0.8408, 0.8432, 0.8443, 0.839, 0.8434, 0.8373, 0.842, 0.8409, 0.8438, 0.8416, 0.8437, 0.8424, 0.8365, 0.8374, 0.8382, 0.8376, 0.8452, 0.8382, 0.8366, 0.8342, 0.8445, 0.8401, 0.841, 0.8412, 0.8432, 0.8417, 0.8461, 0.8401, 0.8402, 0.8389, 0.8401, 0.8366, 0.8419, 0.8414, 0.8439, 0.84, 0.8384, 0.8297, 0.8401, 0.8445, 0.8406, 0.8432, 0.8442, 0.8458, 0.8442, 0.8428, 0.8432, 0.8418, 0.8404, 0.8461, 0.8359, 0.8407, 0.8429, 0.8469, 0.8436, 0.8494, 0.8425, 0.8445, 0.8419, 0.8412, 0.8415, 0.8437, 0.8431, 0.846, 0.8439, 0.8452, 0.8354, 0.8423]}\n",
      "[0.7235319770716288, 0.8423]\n",
      "RESULT:\n",
      "{'loss': -0.849399983882904, 'real_loss': 0.7235319770716288, 'best_val_loss': 0.6637952419427725, 'best_val_accuracy': 0.849399983882904, 'model_name': 'model_0.8494_0c7c0', 'space': {'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}, 'status': 'ok'}\n",
      "{\n",
      "    \"best_val_accuracy\": 0.849399983882904,\n",
      "    \"best_val_loss\": 0.6637952419427725,\n",
      "    \"loss\": -0.849399983882904,\n",
      "    \"model_name\": \"model_0.8494_0c7c0\",\n",
      "    \"real_loss\": 0.7235319770716288,\n",
      "    \"space\": {\n",
      "        \"activation\": \"relu\",\n",
      "        \"batch_size\": 70.0,\n",
      "        \"conv_dropout_drop_proba\": 0.2319040800996359,\n",
      "        \"conv_hiddn_units_mult\": 0.7004255447579512,\n",
      "        \"conv_kernel_size\": 3.0,\n",
      "        \"conv_pool_res_start_idx\": 2.0,\n",
      "        \"epochs\": 180.0,\n",
      "        \"fc_dropout_drop_proba\": 0.17590859742643258,\n",
      "        \"fc_units_1_mult\": 0.9697958299395057,\n",
      "        \"first_conv\": null,\n",
      "        \"l2_weight_reg_mult\": 3.3401336643592123,\n",
      "        \"lr_rate_mult\": 0.6582150163080535,\n",
      "        \"nb_conv_pool_layers\": 2,\n",
      "        \"one_more_fc\": 1.1848111467718283,\n",
      "        \"optimizer\": \"Adam\",\n",
      "        \"pooling_type\": \"inception\",\n",
      "        \"res_conv_kernel_size\": 3.0,\n",
      "        \"residual\": null,\n",
      "        \"use_BN\": true\n",
      "    },\n",
      "    \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model, model_name, results, log_path = build_and_train(\n",
    "        best_space_model,\n",
    "        save_best_weights=True,\n",
    "        log_for_tensorboard=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "_, test_it = h.construct_data_generator(batch_size=70, target_size=(128,128), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7235320825260002, 0.8423]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': -0.849399983882904,\n",
       " 'real_loss': 0.7235319770716288,\n",
       " 'best_val_loss': 0.6637952419427725,\n",
       " 'best_val_accuracy': 0.849399983882904,\n",
       " 'model_name': 'model_0.8494_0c7c0',\n",
       " 'space': {'activation': 'relu',\n",
       "  'batch_size': 70.0,\n",
       "  'conv_dropout_drop_proba': 0.2319040800996359,\n",
       "  'conv_hiddn_units_mult': 0.7004255447579512,\n",
       "  'conv_kernel_size': 3.0,\n",
       "  'conv_pool_res_start_idx': 2.0,\n",
       "  'epochs': 180.0,\n",
       "  'fc_dropout_drop_proba': 0.17590859742643258,\n",
       "  'fc_units_1_mult': 0.9697958299395057,\n",
       "  'first_conv': None,\n",
       "  'l2_weight_reg_mult': 3.3401336643592123,\n",
       "  'lr_rate_mult': 0.6582150163080535,\n",
       "  'nb_conv_pool_layers': 2,\n",
       "  'one_more_fc': 1.1848111467718283,\n",
       "  'optimizer': 'Adam',\n",
       "  'pooling_type': 'inception',\n",
       "  'res_conv_kernel_size': 3.0,\n",
       "  'residual': None,\n",
       "  'use_BN': True},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights/940a3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7104610025465905, 0.8494]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "y_true = h.y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4989\n",
      "           1       0.85      0.85      0.85      5011\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4222, 0.0767],\n",
       "       [0.0739, 0.4272]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax= plt.subplot()\n",
    "sn.heatmap(confusion_matrix(y_true, y_pred), \n",
    "           annot=True, fmt='g', cmap=cm.RdBu_r, ax = ax, cbar=False)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['trigg 1', 'trigg 3']); ax.yaxis.set_ticklabels(['trigg 1', 'trigg 3']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
