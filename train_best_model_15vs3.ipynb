{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helper\n",
    "from neural_net import build_and_train\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Helper('topomaps_15vs3/train/combined', 'topomaps_15vs3/test/combined', 'results/1vs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_space_model = h.load_best_hyperspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 70.0,\n",
       " 'conv_dropout_drop_proba': 0.2319040800996359,\n",
       " 'conv_hiddn_units_mult': 0.7004255447579512,\n",
       " 'conv_kernel_size': 3.0,\n",
       " 'conv_pool_res_start_idx': 2.0,\n",
       " 'epochs': 180.0,\n",
       " 'fc_dropout_drop_proba': 0.17590859742643258,\n",
       " 'fc_units_1_mult': 0.9697958299395057,\n",
       " 'first_conv': None,\n",
       " 'l2_weight_reg_mult': 3.3401336643592123,\n",
       " 'lr_rate_mult': 0.6582150163080535,\n",
       " 'nb_conv_pool_layers': 2,\n",
       " 'one_more_fc': 1.1848111467718283,\n",
       " 'optimizer': 'Adam',\n",
       " 'pooling_type': 'inception',\n",
       " 'res_conv_kernel_size': 3.0,\n",
       " 'residual': None,\n",
       " 'use_BN': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_space_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Hyperspace:\n",
      "{'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}\n",
      "0\n",
      "28\n",
      "(None, 128, 128, 3)\n",
      "(None, 128, 128, 28)\n",
      "(None, 64, 64, 36)\n",
      "1\n",
      "56\n",
      "(None, 64, 64, 36)\n",
      "(None, 64, 64, 56)\n",
      "(None, 32, 32, 69)\n",
      "(None, 70656)\n",
      "(None, 969)\n",
      "(None, 888)\n",
      "Model's weights will be saved to: weights/9b88b.hdf5\n",
      "Tensorboard log files will be saved to: TensorBoard/9b88b\n",
      "Epoch 1/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 6.5855 - accuracy: 0.5029 - val_loss: 5.2833 - val_accuracy: 0.5072\n",
      "Epoch 2/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 4.4248 - accuracy: 0.5075 - val_loss: 3.7453 - val_accuracy: 0.4989\n",
      "Epoch 3/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 3.2828 - accuracy: 0.5016 - val_loss: 2.8952 - val_accuracy: 0.4989\n",
      "Epoch 4/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 2.6192 - accuracy: 0.5003 - val_loss: 2.3808 - val_accuracy: 0.4989\n",
      "Epoch 5/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 2.1986 - accuracy: 0.5010 - val_loss: 2.0355 - val_accuracy: 0.4989\n",
      "Epoch 6/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 1.9037 - accuracy: 0.4981 - val_loss: 1.7824 - val_accuracy: 0.4989\n",
      "Epoch 7/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 1.6820 - accuracy: 0.4987 - val_loss: 1.5914 - val_accuracy: 0.4989\n",
      "Epoch 8/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 1.5132 - accuracy: 0.5002 - val_loss: 1.4393 - val_accuracy: 0.4989\n",
      "Epoch 9/180\n",
      "572/572 [==============================] - 147s 258ms/step - loss: 1.3746 - accuracy: 0.5017 - val_loss: 1.3138 - val_accuracy: 0.4989\n",
      "Epoch 10/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 1.2603 - accuracy: 0.5028 - val_loss: 1.2100 - val_accuracy: 0.4989\n",
      "Epoch 11/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 1.1665 - accuracy: 0.5062 - val_loss: 1.1254 - val_accuracy: 0.4989\n",
      "Epoch 12/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 1.0901 - accuracy: 0.5044 - val_loss: 1.0570 - val_accuracy: 0.5064\n",
      "Epoch 13/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 1.0292 - accuracy: 0.5081 - val_loss: 1.0029 - val_accuracy: 0.4995\n",
      "Epoch 14/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 0.9795 - accuracy: 0.5264 - val_loss: 0.9560 - val_accuracy: 0.5453\n",
      "Epoch 15/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.9396 - accuracy: 0.5458 - val_loss: 0.9239 - val_accuracy: 0.5566\n",
      "Epoch 16/180\n",
      "572/572 [==============================] - 144s 253ms/step - loss: 0.9104 - accuracy: 0.5567 - val_loss: 0.8970 - val_accuracy: 0.5669\n",
      "Epoch 17/180\n",
      "572/572 [==============================] - 147s 256ms/step - loss: 0.8891 - accuracy: 0.5664 - val_loss: 0.8819 - val_accuracy: 0.5666\n",
      "Epoch 18/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 0.8709 - accuracy: 0.5823 - val_loss: 0.8628 - val_accuracy: 0.5892\n",
      "Epoch 19/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.8557 - accuracy: 0.5940 - val_loss: 0.8498 - val_accuracy: 0.6113\n",
      "Epoch 20/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.8402 - accuracy: 0.6141 - val_loss: 0.8369 - val_accuracy: 0.6257\n",
      "Epoch 21/180\n",
      "572/572 [==============================] - 147s 258ms/step - loss: 0.8274 - accuracy: 0.6283 - val_loss: 0.8207 - val_accuracy: 0.6501\n",
      "Epoch 22/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.8133 - accuracy: 0.6457 - val_loss: 0.8118 - val_accuracy: 0.6483\n",
      "Epoch 23/180\n",
      "572/572 [==============================] - 147s 256ms/step - loss: 0.7967 - accuracy: 0.6608 - val_loss: 0.7932 - val_accuracy: 0.6659\n",
      "Epoch 24/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.7820 - accuracy: 0.6746 - val_loss: 0.7833 - val_accuracy: 0.6754\n",
      "Epoch 25/180\n",
      "572/572 [==============================] - 154s 270ms/step - loss: 0.7683 - accuracy: 0.6869 - val_loss: 0.7677 - val_accuracy: 0.6895\n",
      "Epoch 26/180\n",
      "572/572 [==============================] - 149s 260ms/step - loss: 0.7554 - accuracy: 0.6966 - val_loss: 0.7591 - val_accuracy: 0.6972\n",
      "Epoch 27/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 0.7452 - accuracy: 0.7040 - val_loss: 0.7441 - val_accuracy: 0.7092\n",
      "Epoch 28/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.7309 - accuracy: 0.7158 - val_loss: 0.7381 - val_accuracy: 0.7144\n",
      "Epoch 29/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.7198 - accuracy: 0.7276 - val_loss: 0.7335 - val_accuracy: 0.7156\n",
      "Epoch 30/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.7087 - accuracy: 0.7328 - val_loss: 0.7209 - val_accuracy: 0.7286\n",
      "Epoch 31/180\n",
      "572/572 [==============================] - 152s 266ms/step - loss: 0.6988 - accuracy: 0.7413 - val_loss: 0.7107 - val_accuracy: 0.7295\n",
      "Epoch 32/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.6897 - accuracy: 0.7473 - val_loss: 0.7057 - val_accuracy: 0.7381\n",
      "Epoch 33/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.6815 - accuracy: 0.7527 - val_loss: 0.6959 - val_accuracy: 0.7424\n",
      "Epoch 34/180\n",
      "572/572 [==============================] - 152s 265ms/step - loss: 0.6714 - accuracy: 0.7598 - val_loss: 0.6928 - val_accuracy: 0.7431\n",
      "Epoch 35/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.6595 - accuracy: 0.7659 - val_loss: 0.6881 - val_accuracy: 0.7515\n",
      "Epoch 36/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.6512 - accuracy: 0.7716 - val_loss: 0.6838 - val_accuracy: 0.7492\n",
      "Epoch 37/180\n",
      "572/572 [==============================] - 154s 270ms/step - loss: 0.6418 - accuracy: 0.7789 - val_loss: 0.6800 - val_accuracy: 0.7546\n",
      "Epoch 38/180\n",
      "572/572 [==============================] - 140s 244ms/step - loss: 0.6334 - accuracy: 0.7860 - val_loss: 0.6822 - val_accuracy: 0.7496\n",
      "Epoch 39/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.6240 - accuracy: 0.7902 - val_loss: 0.6693 - val_accuracy: 0.7618\n",
      "Epoch 40/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.6189 - accuracy: 0.7894 - val_loss: 0.6696 - val_accuracy: 0.7594\n",
      "Epoch 41/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.6073 - accuracy: 0.7995 - val_loss: 0.6689 - val_accuracy: 0.7612\n",
      "Epoch 42/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.6018 - accuracy: 0.8023 - val_loss: 0.6755 - val_accuracy: 0.7555\n",
      "Epoch 43/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.5927 - accuracy: 0.8087 - val_loss: 0.6607 - val_accuracy: 0.7686\n",
      "Epoch 44/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.5893 - accuracy: 0.8107 - val_loss: 0.6614 - val_accuracy: 0.7667\n",
      "Epoch 45/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.5808 - accuracy: 0.8131 - val_loss: 0.6519 - val_accuracy: 0.7736\n",
      "Epoch 46/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.5748 - accuracy: 0.8142 - val_loss: 0.6527 - val_accuracy: 0.7720\n",
      "Epoch 47/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 0.5692 - accuracy: 0.8207 - val_loss: 0.6537 - val_accuracy: 0.7743\n",
      "Epoch 48/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.5606 - accuracy: 0.8237 - val_loss: 0.6468 - val_accuracy: 0.7762\n",
      "Epoch 49/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.5509 - accuracy: 0.8309 - val_loss: 0.6599 - val_accuracy: 0.7719\n",
      "Epoch 50/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 148s 259ms/step - loss: 0.5438 - accuracy: 0.8343 - val_loss: 0.6474 - val_accuracy: 0.7787\n",
      "Epoch 51/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.5372 - accuracy: 0.8394 - val_loss: 0.6489 - val_accuracy: 0.7770\n",
      "Epoch 52/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.5321 - accuracy: 0.8415 - val_loss: 0.6601 - val_accuracy: 0.7728\n",
      "Epoch 53/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.5253 - accuracy: 0.8459 - val_loss: 0.6569 - val_accuracy: 0.7769\n",
      "Epoch 54/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.5209 - accuracy: 0.8453 - val_loss: 0.6423 - val_accuracy: 0.7824\n",
      "Epoch 55/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.5138 - accuracy: 0.8514 - val_loss: 0.6683 - val_accuracy: 0.7727\n",
      "Epoch 56/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 0.5060 - accuracy: 0.8565 - val_loss: 0.6521 - val_accuracy: 0.7829\n",
      "Epoch 57/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.4992 - accuracy: 0.8576 - val_loss: 0.6360 - val_accuracy: 0.7839\n",
      "Epoch 58/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.4949 - accuracy: 0.8603 - val_loss: 0.6554 - val_accuracy: 0.7783\n",
      "Epoch 59/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.4910 - accuracy: 0.8620 - val_loss: 0.6481 - val_accuracy: 0.7857\n",
      "Epoch 60/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.4843 - accuracy: 0.8686 - val_loss: 0.6568 - val_accuracy: 0.7830\n",
      "Epoch 61/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 0.4771 - accuracy: 0.8694 - val_loss: 0.6440 - val_accuracy: 0.7913\n",
      "Epoch 62/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.4747 - accuracy: 0.8709 - val_loss: 0.6492 - val_accuracy: 0.7876\n",
      "Epoch 63/180\n",
      "572/572 [==============================] - 146s 254ms/step - loss: 0.4690 - accuracy: 0.8735 - val_loss: 0.6574 - val_accuracy: 0.7843\n",
      "Epoch 64/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.4618 - accuracy: 0.8771 - val_loss: 0.6595 - val_accuracy: 0.7837\n",
      "Epoch 65/180\n",
      "572/572 [==============================] - 146s 256ms/step - loss: 0.4596 - accuracy: 0.8786 - val_loss: 0.6489 - val_accuracy: 0.7912\n",
      "Epoch 66/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.4536 - accuracy: 0.8817 - val_loss: 0.6489 - val_accuracy: 0.7910\n",
      "Epoch 67/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 0.4474 - accuracy: 0.8828 - val_loss: 0.6554 - val_accuracy: 0.7895\n",
      "Epoch 68/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.4435 - accuracy: 0.8873 - val_loss: 0.6539 - val_accuracy: 0.7884\n",
      "Epoch 69/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 0.4401 - accuracy: 0.8881 - val_loss: 0.6629 - val_accuracy: 0.7870\n",
      "Epoch 70/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.4301 - accuracy: 0.8942 - val_loss: 0.6615 - val_accuracy: 0.7899\n",
      "Epoch 71/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.4260 - accuracy: 0.8952 - val_loss: 0.6652 - val_accuracy: 0.7899\n",
      "Epoch 72/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.4222 - accuracy: 0.8967 - val_loss: 0.6677 - val_accuracy: 0.7898\n",
      "Epoch 73/180\n",
      "572/572 [==============================] - 146s 256ms/step - loss: 0.4210 - accuracy: 0.8977 - val_loss: 0.6751 - val_accuracy: 0.7881\n",
      "Epoch 74/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.4155 - accuracy: 0.9007 - val_loss: 0.6768 - val_accuracy: 0.7867\n",
      "Epoch 75/180\n",
      "572/572 [==============================] - 147s 258ms/step - loss: 0.4094 - accuracy: 0.9040 - val_loss: 0.6761 - val_accuracy: 0.7849\n",
      "Epoch 76/180\n",
      "572/572 [==============================] - 146s 256ms/step - loss: 0.4036 - accuracy: 0.9076 - val_loss: 0.6759 - val_accuracy: 0.7879\n",
      "Epoch 77/180\n",
      "572/572 [==============================] - 151s 265ms/step - loss: 0.4028 - accuracy: 0.9064 - val_loss: 0.6713 - val_accuracy: 0.7918\n",
      "Epoch 78/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3962 - accuracy: 0.9110 - val_loss: 0.6817 - val_accuracy: 0.7895\n",
      "Epoch 79/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3930 - accuracy: 0.9114 - val_loss: 0.6919 - val_accuracy: 0.7892\n",
      "Epoch 80/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3878 - accuracy: 0.9135 - val_loss: 0.6898 - val_accuracy: 0.7921\n",
      "Epoch 81/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 0.3829 - accuracy: 0.9184 - val_loss: 0.6941 - val_accuracy: 0.7883\n",
      "Epoch 82/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3801 - accuracy: 0.9162 - val_loss: 0.7107 - val_accuracy: 0.7879\n",
      "Epoch 83/180\n",
      "572/572 [==============================] - 144s 253ms/step - loss: 0.3736 - accuracy: 0.9209 - val_loss: 0.6937 - val_accuracy: 0.7910\n",
      "Epoch 84/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3706 - accuracy: 0.9227 - val_loss: 0.6865 - val_accuracy: 0.7921\n",
      "Epoch 85/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 0.3712 - accuracy: 0.9219 - val_loss: 0.7039 - val_accuracy: 0.7880\n",
      "Epoch 86/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3671 - accuracy: 0.9242 - val_loss: 0.7020 - val_accuracy: 0.7897\n",
      "Epoch 87/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.3621 - accuracy: 0.9254 - val_loss: 0.7102 - val_accuracy: 0.7923\n",
      "Epoch 88/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3602 - accuracy: 0.9272 - val_loss: 0.7076 - val_accuracy: 0.7927\n",
      "Epoch 89/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3529 - accuracy: 0.9298 - val_loss: 0.7179 - val_accuracy: 0.7891\n",
      "Epoch 90/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.3533 - accuracy: 0.9301 - val_loss: 0.7122 - val_accuracy: 0.7900\n",
      "Epoch 91/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3488 - accuracy: 0.9344 - val_loss: 0.7140 - val_accuracy: 0.7911\n",
      "Epoch 92/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3468 - accuracy: 0.9332 - val_loss: 0.7282 - val_accuracy: 0.7899\n",
      "Epoch 93/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3419 - accuracy: 0.9368 - val_loss: 0.7232 - val_accuracy: 0.7914\n",
      "Epoch 94/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3379 - accuracy: 0.9383 - val_loss: 0.7524 - val_accuracy: 0.7811\n",
      "Epoch 95/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3339 - accuracy: 0.9397 - val_loss: 0.7291 - val_accuracy: 0.7919\n",
      "Epoch 96/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3311 - accuracy: 0.9406 - val_loss: 0.7235 - val_accuracy: 0.7923\n",
      "Epoch 97/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3330 - accuracy: 0.9404 - val_loss: 0.7392 - val_accuracy: 0.7879\n",
      "Epoch 98/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3283 - accuracy: 0.9413 - val_loss: 0.7356 - val_accuracy: 0.7899\n",
      "Epoch 99/180\n",
      "572/572 [==============================] - 144s 253ms/step - loss: 0.3255 - accuracy: 0.9426 - val_loss: 0.7481 - val_accuracy: 0.7913\n",
      "Epoch 100/180\n",
      "572/572 [==============================] - 153s 267ms/step - loss: 0.3227 - accuracy: 0.9453 - val_loss: 0.7450 - val_accuracy: 0.7928\n",
      "Epoch 101/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3204 - accuracy: 0.9463 - val_loss: 0.7475 - val_accuracy: 0.7898\n",
      "Epoch 102/180\n",
      "572/572 [==============================] - 142s 247ms/step - loss: 0.3176 - accuracy: 0.9472 - val_loss: 0.7578 - val_accuracy: 0.7890\n",
      "Epoch 103/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3156 - accuracy: 0.9482 - val_loss: 0.7650 - val_accuracy: 0.7891\n",
      "Epoch 104/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.3134 - accuracy: 0.9504 - val_loss: 0.7596 - val_accuracy: 0.7884\n",
      "Epoch 105/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 147s 257ms/step - loss: 0.3105 - accuracy: 0.9509 - val_loss: 0.7531 - val_accuracy: 0.7935\n",
      "Epoch 106/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3069 - accuracy: 0.9525 - val_loss: 0.7592 - val_accuracy: 0.7909\n",
      "Epoch 107/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.3086 - accuracy: 0.9501 - val_loss: 0.7778 - val_accuracy: 0.7887\n",
      "Epoch 108/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3084 - accuracy: 0.9504 - val_loss: 0.7504 - val_accuracy: 0.7941\n",
      "Epoch 109/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2997 - accuracy: 0.9561 - val_loss: 0.7624 - val_accuracy: 0.7917\n",
      "Epoch 110/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2989 - accuracy: 0.9557 - val_loss: 0.7898 - val_accuracy: 0.7866\n",
      "Epoch 111/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.3006 - accuracy: 0.9544 - val_loss: 0.7790 - val_accuracy: 0.7875\n",
      "Epoch 112/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2954 - accuracy: 0.9561 - val_loss: 0.7867 - val_accuracy: 0.7932\n",
      "Epoch 113/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.2938 - accuracy: 0.9568 - val_loss: 0.7828 - val_accuracy: 0.7916\n",
      "Epoch 114/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2953 - accuracy: 0.9568 - val_loss: 0.7847 - val_accuracy: 0.7924\n",
      "Epoch 115/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2908 - accuracy: 0.9585 - val_loss: 0.7890 - val_accuracy: 0.7916\n",
      "Epoch 116/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.2858 - accuracy: 0.9606 - val_loss: 0.7877 - val_accuracy: 0.7937\n",
      "Epoch 117/180\n",
      "572/572 [==============================] - 158s 276ms/step - loss: 0.2865 - accuracy: 0.9603 - val_loss: 0.7718 - val_accuracy: 0.7950\n",
      "Epoch 118/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.2833 - accuracy: 0.9607 - val_loss: 0.7974 - val_accuracy: 0.7900\n",
      "Epoch 119/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2820 - accuracy: 0.9623 - val_loss: 0.7972 - val_accuracy: 0.7900\n",
      "Epoch 120/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2857 - accuracy: 0.9605 - val_loss: 0.7860 - val_accuracy: 0.7905\n",
      "Epoch 121/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2770 - accuracy: 0.9640 - val_loss: 0.7979 - val_accuracy: 0.7886\n",
      "Epoch 122/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2816 - accuracy: 0.9620 - val_loss: 0.7894 - val_accuracy: 0.7943\n",
      "Epoch 123/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2785 - accuracy: 0.9632 - val_loss: 0.8148 - val_accuracy: 0.7895\n",
      "Epoch 124/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2748 - accuracy: 0.9651 - val_loss: 0.7992 - val_accuracy: 0.7898\n",
      "Epoch 125/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2745 - accuracy: 0.9651 - val_loss: 0.8342 - val_accuracy: 0.7865\n",
      "Epoch 126/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2718 - accuracy: 0.9675 - val_loss: 0.8358 - val_accuracy: 0.7897\n",
      "Epoch 127/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2719 - accuracy: 0.9663 - val_loss: 0.8004 - val_accuracy: 0.7891\n",
      "Epoch 128/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2731 - accuracy: 0.9656 - val_loss: 0.8122 - val_accuracy: 0.7948\n",
      "Epoch 129/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2671 - accuracy: 0.9686 - val_loss: 0.8156 - val_accuracy: 0.7909\n",
      "Epoch 130/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2679 - accuracy: 0.9684 - val_loss: 0.8357 - val_accuracy: 0.7874\n",
      "Epoch 131/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2653 - accuracy: 0.9695 - val_loss: 0.8158 - val_accuracy: 0.7937\n",
      "Epoch 132/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2628 - accuracy: 0.9704 - val_loss: 0.8376 - val_accuracy: 0.7940\n",
      "Epoch 133/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2643 - accuracy: 0.9686 - val_loss: 0.8329 - val_accuracy: 0.7934\n",
      "Epoch 134/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2630 - accuracy: 0.9695 - val_loss: 0.8302 - val_accuracy: 0.7907\n",
      "Epoch 135/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2634 - accuracy: 0.9693 - val_loss: 0.8248 - val_accuracy: 0.7905\n",
      "Epoch 136/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2619 - accuracy: 0.9698 - val_loss: 0.8227 - val_accuracy: 0.7940\n",
      "Epoch 137/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2588 - accuracy: 0.9708 - val_loss: 0.8171 - val_accuracy: 0.7924\n",
      "Epoch 138/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2558 - accuracy: 0.9729 - val_loss: 0.8756 - val_accuracy: 0.7789\n",
      "Epoch 139/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2586 - accuracy: 0.9704 - val_loss: 0.8384 - val_accuracy: 0.7900\n",
      "Epoch 140/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2553 - accuracy: 0.9729 - val_loss: 0.8405 - val_accuracy: 0.7870\n",
      "Epoch 141/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2544 - accuracy: 0.9722 - val_loss: 0.8215 - val_accuracy: 0.7918\n",
      "Epoch 142/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2543 - accuracy: 0.9728 - val_loss: 0.8512 - val_accuracy: 0.7930\n",
      "Epoch 143/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2542 - accuracy: 0.9733 - val_loss: 0.8629 - val_accuracy: 0.7836\n",
      "Epoch 144/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2499 - accuracy: 0.9747 - val_loss: 0.8643 - val_accuracy: 0.7882\n",
      "Epoch 145/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2491 - accuracy: 0.9749 - val_loss: 0.8301 - val_accuracy: 0.7904\n",
      "Epoch 146/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2494 - accuracy: 0.9750 - val_loss: 0.8348 - val_accuracy: 0.7935\n",
      "Epoch 147/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2500 - accuracy: 0.9743 - val_loss: 0.8450 - val_accuracy: 0.7901\n",
      "Epoch 148/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2519 - accuracy: 0.9740 - val_loss: 0.8424 - val_accuracy: 0.7925\n",
      "Epoch 149/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2486 - accuracy: 0.9757 - val_loss: 0.8550 - val_accuracy: 0.7893\n",
      "Epoch 150/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2429 - accuracy: 0.9773 - val_loss: 0.8460 - val_accuracy: 0.7947\n",
      "Epoch 151/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2450 - accuracy: 0.9756 - val_loss: 0.8441 - val_accuracy: 0.7944\n",
      "Epoch 152/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2454 - accuracy: 0.9759 - val_loss: 0.8476 - val_accuracy: 0.7938\n",
      "Epoch 153/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2415 - accuracy: 0.9772 - val_loss: 0.8447 - val_accuracy: 0.7879\n",
      "Epoch 154/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2427 - accuracy: 0.9762 - val_loss: 0.8615 - val_accuracy: 0.7864\n",
      "Epoch 155/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2426 - accuracy: 0.9776 - val_loss: 0.8497 - val_accuracy: 0.7888\n",
      "Epoch 156/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2374 - accuracy: 0.9793 - val_loss: 0.8640 - val_accuracy: 0.7877\n",
      "Epoch 157/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2408 - accuracy: 0.9774 - val_loss: 0.8733 - val_accuracy: 0.7890\n",
      "Epoch 158/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2387 - accuracy: 0.9779 - val_loss: 0.8449 - val_accuracy: 0.7924\n",
      "Epoch 159/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2373 - accuracy: 0.9787 - val_loss: 0.8629 - val_accuracy: 0.7904\n",
      "Epoch 160/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2341 - accuracy: 0.9800 - val_loss: 0.8538 - val_accuracy: 0.7943\n",
      "Epoch 161/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2373 - accuracy: 0.9783 - val_loss: 0.8540 - val_accuracy: 0.7906\n",
      "Epoch 162/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2367 - accuracy: 0.9792 - val_loss: 0.8367 - val_accuracy: 0.7898\n",
      "Epoch 163/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2327 - accuracy: 0.9803 - val_loss: 0.8567 - val_accuracy: 0.7919\n",
      "Epoch 164/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2323 - accuracy: 0.9800 - val_loss: 0.8620 - val_accuracy: 0.7914\n",
      "Epoch 165/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2352 - accuracy: 0.9789 - val_loss: 0.8513 - val_accuracy: 0.7909\n",
      "Epoch 166/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2340 - accuracy: 0.9791 - val_loss: 0.8489 - val_accuracy: 0.7962\n",
      "Epoch 167/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2307 - accuracy: 0.9814 - val_loss: 0.8511 - val_accuracy: 0.7922\n",
      "Epoch 168/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2327 - accuracy: 0.9789 - val_loss: 0.8442 - val_accuracy: 0.7913\n",
      "Epoch 169/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2315 - accuracy: 0.9804 - val_loss: 0.8516 - val_accuracy: 0.7915\n",
      "Epoch 170/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2254 - accuracy: 0.9826 - val_loss: 0.8484 - val_accuracy: 0.7908\n",
      "Epoch 171/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2288 - accuracy: 0.9811 - val_loss: 0.8547 - val_accuracy: 0.7926\n",
      "Epoch 172/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2287 - accuracy: 0.9810 - val_loss: 0.8693 - val_accuracy: 0.7862\n",
      "Epoch 173/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2274 - accuracy: 0.9815 - val_loss: 0.8578 - val_accuracy: 0.7905\n",
      "Epoch 174/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2279 - accuracy: 0.9811 - val_loss: 0.8618 - val_accuracy: 0.7904\n",
      "Epoch 175/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2264 - accuracy: 0.9822 - val_loss: 0.8572 - val_accuracy: 0.7905\n",
      "Epoch 176/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2277 - accuracy: 0.9812 - val_loss: 0.8541 - val_accuracy: 0.7924\n",
      "Epoch 177/180\n",
      "572/572 [==============================] - 144s 253ms/step - loss: 0.2248 - accuracy: 0.9829 - val_loss: 0.8617 - val_accuracy: 0.7896\n",
      "Epoch 178/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.2225 - accuracy: 0.9833 - val_loss: 0.8672 - val_accuracy: 0.7924\n",
      "Epoch 179/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.2229 - accuracy: 0.9830 - val_loss: 0.8636 - val_accuracy: 0.7914\n",
      "Epoch 180/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.2222 - accuracy: 0.9829 - val_loss: 0.8603 - val_accuracy: 0.7926\n",
      "Model name: model_0.7962_017dd\n",
      "0.7962\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "{'loss': [6.5842409690618515, 4.425021547317505, 3.2828860436081886, 2.618936737000942, 2.1986794164180754, 1.903794130384922, 1.682022107720375, 1.5131650079488754, 1.3746957020163537, 1.260268135100603, 1.1664708726406097, 1.0901279337108136, 1.0291899892240763, 0.979486425280571, 0.9396337303221226, 0.9104083626717329, 0.8891393241137266, 0.8709164280295372, 0.8558524246215821, 0.8402745504081249, 0.8274356714785099, 0.8132184955179691, 0.7966684170067311, 0.78208134098351, 0.768210482031107, 0.7554202721714973, 0.7450730285644531, 0.7308333343416452, 0.7198278057128191, 0.7087345982640981, 0.6988094411790371, 0.6897952463179827, 0.681484227091074, 0.6713220961540938, 0.6594593129307031, 0.651315983697772, 0.641889026850462, 0.6334219856262207, 0.6239924388080835, 0.6190400152876974, 0.607446935094893, 0.6018174556270242, 0.5924875657260418, 0.5892269342616201, 0.5809204109013081, 0.5749158800169826, 0.5692857203558087, 0.5606385691985488, 0.5507756523042917, 0.5438528396487236, 0.5371149207428098, 0.5320645063146949, 0.52530943608284, 0.5209120662882925, 0.5137281704992056, 0.5058766303136945, 0.499230699531734, 0.49503827331960204, 0.49093026586622, 0.4842419023886323, 0.47705104676634075, 0.4748624526783824, 0.4689003593847156, 0.46172988503426315, 0.45959941451996567, 0.45364742139726877, 0.4473862029984593, 0.4435727266818285, 0.44000315573066473, 0.4300918137207627, 0.42611736918240783, 0.4221363697350025, 0.42107732604444026, 0.4155917207673192, 0.4094979786276817, 0.4036580082923174, 0.40283654994517565, 0.3961613719314337, 0.3929279502332211, 0.3877900824025273, 0.3828251445889473, 0.38017817264050247, 0.3736346089467406, 0.37060737613961103, 0.3712135597169399, 0.3671367808878422, 0.36207219065353274, 0.3603410469256341, 0.3528430374823511, 0.3532298905849457, 0.348854850590229, 0.34682985570281744, 0.3419244020432234, 0.33791543648019434, 0.3339101626165211, 0.33101728823035953, 0.33315426602587106, 0.3283711575567722, 0.32549743630737066, 0.3227877694219351, 0.32042314037308095, 0.31757746913284063, 0.31565733574703336, 0.3133693360760808, 0.31044568664580585, 0.30683603188395503, 0.3084849768728018, 0.3083865990005434, 0.29976859948039053, 0.2988132752105594, 0.3004838597923517, 0.29538148137927056, 0.29374559693410995, 0.29524312510713935, 0.29083234288543464, 0.2858544024042785, 0.2863907712958753, 0.28334386875107886, 0.282021250218153, 0.28578691064193845, 0.27694169512763617, 0.28166842383891344, 0.2785977012626827, 0.2748103928975761, 0.2745374614447355, 0.2718828003406525, 0.27199546033516525, 0.2731318782567978, 0.26712676440924404, 0.26792643978446723, 0.26532790864259004, 0.2628395607843995, 0.26437324489280584, 0.26309008242934945, 0.26342063631117346, 0.26184493949636817, 0.2588742925487459, 0.2558215767033398, 0.2584927300363779, 0.2552780930623412, 0.2543874264396727, 0.2543091862052679, 0.25419349148124454, 0.2498129731602967, 0.24912060433998703, 0.24933836103975773, 0.25000946221128106, 0.25182454495504497, 0.24858652735501527, 0.24285414739698172, 0.24499516888335346, 0.24546886656433345, 0.2415004468038678, 0.2426772739626467, 0.2425823153965175, 0.23739575799927115, 0.24086965929344298, 0.23874004786461592, 0.23730197473987938, 0.23417750058323145, 0.2372966635413468, 0.23672729210183024, 0.23277246199175716, 0.23225281772390008, 0.23526656782999636, 0.23388180869072675, 0.23077808982133866, 0.23267104154080154, 0.23154606596007943, 0.2253800342567265, 0.22880832758545874, 0.22874388115108013, 0.2274036592170596, 0.22795108492672445, 0.22644998106732964, 0.2276925876252353, 0.22473011757805944, 0.22250299794971942, 0.22288070378825067, 0.22218797569349408], 'accuracy': [0.5029, 0.507525, 0.501575, 0.500275, 0.501, 0.498075, 0.498725, 0.50025, 0.5017, 0.5028, 0.506175, 0.504425, 0.50815, 0.5264, 0.545775, 0.556725, 0.5664, 0.582275, 0.59405, 0.6141, 0.6283, 0.645725, 0.66085, 0.674625, 0.6869, 0.6966, 0.703975, 0.715775, 0.72765, 0.732825, 0.7413, 0.7473, 0.752675, 0.759775, 0.76585, 0.771575, 0.77885, 0.786025, 0.790175, 0.78945, 0.79955, 0.80235, 0.808725, 0.810725, 0.813075, 0.81425, 0.820675, 0.823725, 0.830875, 0.834275, 0.839425, 0.84155, 0.845925, 0.84525, 0.851425, 0.85655, 0.857575, 0.860325, 0.86205, 0.86855, 0.86945, 0.8709, 0.8735, 0.877075, 0.878625, 0.88175, 0.882825, 0.887325, 0.88805, 0.8942, 0.895225, 0.89675, 0.897675, 0.90065, 0.904025, 0.907625, 0.906375, 0.911025, 0.911425, 0.9135, 0.9184, 0.916225, 0.920875, 0.9227, 0.92195, 0.924175, 0.9254, 0.9272, 0.9298, 0.930075, 0.9344, 0.9332, 0.936825, 0.938275, 0.939725, 0.94055, 0.940375, 0.94125, 0.94255, 0.945325, 0.946275, 0.9472, 0.94825, 0.9504, 0.95085, 0.952525, 0.950125, 0.950375, 0.956075, 0.95575, 0.9544, 0.9561, 0.956775, 0.95685, 0.958525, 0.960625, 0.960275, 0.9607, 0.9623, 0.9605, 0.963975, 0.962025, 0.9632, 0.965075, 0.96515, 0.967475, 0.966275, 0.96555, 0.96855, 0.968425, 0.969525, 0.970375, 0.968575, 0.969525, 0.96925, 0.969775, 0.97085, 0.97285, 0.97045, 0.97295, 0.972175, 0.97275, 0.97335, 0.974675, 0.974875, 0.974975, 0.974275, 0.973975, 0.975725, 0.977325, 0.9756, 0.9759, 0.97725, 0.9762, 0.9776, 0.979275, 0.977375, 0.97785, 0.9787, 0.980025, 0.97835, 0.9792, 0.98025, 0.980025, 0.978875, 0.979075, 0.9814, 0.978925, 0.98045, 0.9826, 0.9811, 0.980975, 0.98155, 0.98105, 0.982225, 0.9812, 0.98285, 0.9833, 0.98305, 0.982875], 'val_loss': [5.283274103711535, 3.745328424693821, 2.8952155446672774, 2.3807711051060605, 2.035507755679684, 1.7824111526662654, 1.591445907012566, 1.439330708730471, 1.3137613068093787, 1.2100331633241026, 1.12544724074277, 1.0570465834824356, 1.0029113109295185, 0.9560093479556637, 0.9238997039261397, 0.8969558435720164, 0.881896458305679, 0.8628069037324065, 0.8497540992456716, 0.8368798173390902, 0.8206514520244999, 0.8118495070017301, 0.7932449479203124, 0.7833094409295729, 0.7676522269115581, 0.759056000025956, 0.7441017819451285, 0.7381039703642571, 0.733547008537746, 0.7209405436382427, 0.7107165772598106, 0.7056777393901265, 0.6958685767400515, 0.692819392764485, 0.6881143775853243, 0.6837670807238225, 0.679976435808035, 0.6821818018293048, 0.6692710364615166, 0.6696213754740629, 0.6688969131116267, 0.6754796529983307, 0.6606867736452943, 0.6613647850243362, 0.6519022967431929, 0.652717092862496, 0.6537167186086829, 0.6468427085376286, 0.6599035121344187, 0.6474324760737119, 0.6489268170370088, 0.6601405579310197, 0.6568615930480557, 0.642293263982226, 0.668329723648258, 0.6520861683191953, 0.6359606922923268, 0.6553873819904728, 0.6480942185108478, 0.656838904727589, 0.6440320873593951, 0.6491654246420293, 0.6574488492695602, 0.6595052930858586, 0.6488519448500413, 0.6489127705564032, 0.6553531593376106, 0.6539308022369038, 0.6629141648332556, 0.6614695562349333, 0.6651773932096842, 0.667709686330982, 0.6751480461000563, 0.6767933860525385, 0.6761038320047872, 0.6758910642637239, 0.6712534611041729, 0.6817019410900302, 0.6918676128754249, 0.6898235978780093, 0.6940865908469354, 0.7107318135408255, 0.6936816848241366, 0.6864775287938285, 0.7039109430946671, 0.7020388199732854, 0.710243781129797, 0.7075959635781242, 0.717942775546254, 0.7122077862699548, 0.7139743435216117, 0.7281590725158478, 0.7231893731163932, 0.7523597172507039, 0.7291314603982272, 0.7235484700519722, 0.7391999939104894, 0.735574631424217, 0.7480795318846936, 0.745026538005242, 0.7474954895206265, 0.7578008862642142, 0.7650213837623596, 0.7595670890141201, 0.75310700131463, 0.7591971736271065, 0.7778477549969733, 0.7504417158506967, 0.762434388790931, 0.7898213188131372, 0.7789525227113203, 0.7866912853050899, 0.7828326471202023, 0.7847070714810511, 0.7890145720301808, 0.787745641244875, 0.771837298269872, 0.797358246741595, 0.7972443351795623, 0.7860317892961569, 0.7978985034502469, 0.7894490955176053, 0.8148043747548457, 0.7992412689682487, 0.8341961532205968, 0.8357993278886888, 0.8004261609557626, 0.8122341230615869, 0.815583397875299, 0.8357389323361271, 0.8157584531740709, 0.8376318958255794, 0.8328894455949744, 0.8301621048183708, 0.8247782800581072, 0.822747085894738, 0.8171270741866186, 0.8755530387788386, 0.838350732843359, 0.8405300418396929, 0.8214617642489347, 0.8512106612845735, 0.8629358062794158, 0.8642916939892136, 0.8300875175249326, 0.8348341336200288, 0.8450411935369452, 0.8423920046616268, 0.8550054405952667, 0.8459840908750788, 0.8441218637919926, 0.8476117094913562, 0.8446664753910544, 0.8614708035142271, 0.8497407125843155, 0.8640375020620706, 0.8732912690489443, 0.8448734404323818, 0.8629207696531203, 0.8538426427574425, 0.8540194334683718, 0.836683512776048, 0.8567088338044974, 0.8619601726531982, 0.851279495062528, 0.8488958557168921, 0.8510972874147908, 0.8442440295552874, 0.8516364799929665, 0.848427813369911, 0.8546542275202024, 0.8692954837025463, 0.8577887345027256, 0.8618095861031458, 0.8571996282447468, 0.8541191147340761, 0.8616771606298593, 0.867150211667681, 0.8635770013699164, 0.8602739607954358], 'val_accuracy': [0.5072, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.4989, 0.5064, 0.4995, 0.5453, 0.5566, 0.5669, 0.5666, 0.5892, 0.6113, 0.6257, 0.6501, 0.6483, 0.6659, 0.6754, 0.6895, 0.6972, 0.7092, 0.7144, 0.7156, 0.7286, 0.7295, 0.7381, 0.7424, 0.7431, 0.7515, 0.7492, 0.7546, 0.7496, 0.7618, 0.7594, 0.7612, 0.7555, 0.7686, 0.7667, 0.7736, 0.772, 0.7743, 0.7762, 0.7719, 0.7787, 0.777, 0.7728, 0.7769, 0.7824, 0.7727, 0.7829, 0.7839, 0.7783, 0.7857, 0.783, 0.7913, 0.7876, 0.7843, 0.7837, 0.7912, 0.791, 0.7895, 0.7884, 0.787, 0.7899, 0.7899, 0.7898, 0.7881, 0.7867, 0.7849, 0.7879, 0.7918, 0.7895, 0.7892, 0.7921, 0.7883, 0.7879, 0.791, 0.7921, 0.788, 0.7897, 0.7923, 0.7927, 0.7891, 0.79, 0.7911, 0.7899, 0.7914, 0.7811, 0.7919, 0.7923, 0.7879, 0.7899, 0.7913, 0.7928, 0.7898, 0.789, 0.7891, 0.7884, 0.7935, 0.7909, 0.7887, 0.7941, 0.7917, 0.7866, 0.7875, 0.7932, 0.7916, 0.7924, 0.7916, 0.7937, 0.795, 0.79, 0.79, 0.7905, 0.7886, 0.7943, 0.7895, 0.7898, 0.7865, 0.7897, 0.7891, 0.7948, 0.7909, 0.7874, 0.7937, 0.794, 0.7934, 0.7907, 0.7905, 0.794, 0.7924, 0.7789, 0.79, 0.787, 0.7918, 0.793, 0.7836, 0.7882, 0.7904, 0.7935, 0.7901, 0.7925, 0.7893, 0.7947, 0.7944, 0.7938, 0.7879, 0.7864, 0.7888, 0.7877, 0.789, 0.7924, 0.7904, 0.7943, 0.7906, 0.7898, 0.7919, 0.7914, 0.7909, 0.7962, 0.7922, 0.7913, 0.7915, 0.7908, 0.7926, 0.7862, 0.7905, 0.7904, 0.7905, 0.7924, 0.7896, 0.7924, 0.7914, 0.7926]}\n",
      "[0.8602739518338983, 0.7926]\n",
      "RESULT:\n",
      "{'loss': -0.7961999773979187, 'real_loss': 0.8602739518338983, 'best_val_loss': 0.6359606922923268, 'best_val_accuracy': 0.7961999773979187, 'model_name': 'model_0.7962_017dd', 'space': {'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}, 'status': 'ok'}\n",
      "{\n",
      "    \"best_val_accuracy\": 0.7961999773979187,\n",
      "    \"best_val_loss\": 0.6359606922923268,\n",
      "    \"loss\": -0.7961999773979187,\n",
      "    \"model_name\": \"model_0.7962_017dd\",\n",
      "    \"real_loss\": 0.8602739518338983,\n",
      "    \"space\": {\n",
      "        \"activation\": \"relu\",\n",
      "        \"batch_size\": 70.0,\n",
      "        \"conv_dropout_drop_proba\": 0.2319040800996359,\n",
      "        \"conv_hiddn_units_mult\": 0.7004255447579512,\n",
      "        \"conv_kernel_size\": 3.0,\n",
      "        \"conv_pool_res_start_idx\": 2.0,\n",
      "        \"epochs\": 180.0,\n",
      "        \"fc_dropout_drop_proba\": 0.17590859742643258,\n",
      "        \"fc_units_1_mult\": 0.9697958299395057,\n",
      "        \"first_conv\": null,\n",
      "        \"l2_weight_reg_mult\": 3.3401336643592123,\n",
      "        \"lr_rate_mult\": 0.6582150163080535,\n",
      "        \"nb_conv_pool_layers\": 2,\n",
      "        \"one_more_fc\": 1.1848111467718283,\n",
      "        \"optimizer\": \"Adam\",\n",
      "        \"pooling_type\": \"inception\",\n",
      "        \"res_conv_kernel_size\": 3.0,\n",
      "        \"residual\": null,\n",
      "        \"use_BN\": true\n",
      "    },\n",
      "    \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model, model_name, results, log_path = build_and_train(\n",
    "        best_space_model,\n",
    "        save_best_weights=True,\n",
    "        log_for_tensorboard=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "_, test_it = h.construct_data_generator(batch_size=70, target_size=(128,128), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8602739607954358, 0.7926]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': -0.7961999773979187,\n",
       " 'real_loss': 0.8602739518338983,\n",
       " 'best_val_loss': 0.6359606922923268,\n",
       " 'best_val_accuracy': 0.7961999773979187,\n",
       " 'model_name': 'model_0.7962_017dd',\n",
       " 'space': {'activation': 'relu',\n",
       "  'batch_size': 70.0,\n",
       "  'conv_dropout_drop_proba': 0.2319040800996359,\n",
       "  'conv_hiddn_units_mult': 0.7004255447579512,\n",
       "  'conv_kernel_size': 3.0,\n",
       "  'conv_pool_res_start_idx': 2.0,\n",
       "  'epochs': 180.0,\n",
       "  'fc_dropout_drop_proba': 0.17590859742643258,\n",
       "  'fc_units_1_mult': 0.9697958299395057,\n",
       "  'first_conv': None,\n",
       "  'l2_weight_reg_mult': 3.3401336643592123,\n",
       "  'lr_rate_mult': 0.6582150163080535,\n",
       "  'nb_conv_pool_layers': 2,\n",
       "  'one_more_fc': 1.1848111467718283,\n",
       "  'optimizer': 'Adam',\n",
       "  'pooling_type': 'inception',\n",
       "  'res_conv_kernel_size': 3.0,\n",
       "  'residual': None,\n",
       "  'use_BN': True},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('15vs3.h5')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights/9b88b.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8488958557168921, 0.7962]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "y_true = h.y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      5011\n",
      "           1       0.78      0.82      0.80      4989\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3863, 0.1148],\n",
       "       [0.089 , 0.4099]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax= plt.subplot()\n",
    "sn.heatmap(confusion_matrix(y_true, y_pred), \n",
    "           annot=True, fmt='g', cmap=cm.RdBu_r, ax = ax, cbar=False)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['trigg 3', 'trigg 1_5']); ax.yaxis.set_ticklabels(['trigg 3', 'trigg 1_5']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
