{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper import Helper\n",
    "from neural_net import build_and_train\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Helper('topomaps_1vs5/train/combined', 'topomaps_1vs5/test/combined', 'results/1vs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_space_model = h.load_best_hyperspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 70.0,\n",
       " 'conv_dropout_drop_proba': 0.2319040800996359,\n",
       " 'conv_hiddn_units_mult': 0.7004255447579512,\n",
       " 'conv_kernel_size': 3.0,\n",
       " 'conv_pool_res_start_idx': 2.0,\n",
       " 'epochs': 180.0,\n",
       " 'fc_dropout_drop_proba': 0.17590859742643258,\n",
       " 'fc_units_1_mult': 0.9697958299395057,\n",
       " 'first_conv': None,\n",
       " 'l2_weight_reg_mult': 3.3401336643592123,\n",
       " 'lr_rate_mult': 0.6582150163080535,\n",
       " 'nb_conv_pool_layers': 2,\n",
       " 'one_more_fc': 1.1848111467718283,\n",
       " 'optimizer': 'Adam',\n",
       " 'pooling_type': 'inception',\n",
       " 'res_conv_kernel_size': 3.0,\n",
       " 'residual': None,\n",
       " 'use_BN': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_space_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Hyperspace:\n",
      "{'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}\n",
      "0\n",
      "28\n",
      "(None, 128, 128, 3)\n",
      "(None, 128, 128, 28)\n",
      "(None, 64, 64, 36)\n",
      "1\n",
      "56\n",
      "(None, 64, 64, 36)\n",
      "(None, 64, 64, 56)\n",
      "(None, 32, 32, 69)\n",
      "(None, 70656)\n",
      "(None, 969)\n",
      "(None, 888)\n",
      "Model's weights will be saved to: weights/424d8.hdf5\n",
      "Tensorboard log files will be saved to: TensorBoard/424d8\n",
      "Epoch 1/180\n",
      "572/572 [==============================] - 151s 263ms/step - loss: 6.8399 - accuracy: 0.5046 - val_loss: 5.7041 - val_accuracy: 0.5007\n",
      "Epoch 2/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 4.8218 - accuracy: 0.5037 - val_loss: 4.0726 - val_accuracy: 0.4989\n",
      "Epoch 3/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 3.5482 - accuracy: 0.5021 - val_loss: 3.1069 - val_accuracy: 0.5016\n",
      "Epoch 4/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 2.7933 - accuracy: 0.5031 - val_loss: 2.5284 - val_accuracy: 0.5011\n",
      "Epoch 5/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 2.3330 - accuracy: 0.4991 - val_loss: 2.1560 - val_accuracy: 0.5011\n",
      "Epoch 6/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 2.0099 - accuracy: 0.4997 - val_loss: 1.8757 - val_accuracy: 0.5011\n",
      "Epoch 7/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 1.7633 - accuracy: 0.5058 - val_loss: 1.6594 - val_accuracy: 0.4993\n",
      "Epoch 8/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 1.5718 - accuracy: 0.5044 - val_loss: 1.4920 - val_accuracy: 0.5011\n",
      "Epoch 9/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 1.4225 - accuracy: 0.5055 - val_loss: 1.3570 - val_accuracy: 0.5011\n",
      "Epoch 10/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 1.2994 - accuracy: 0.5030 - val_loss: 1.2454 - val_accuracy: 0.4989\n",
      "Epoch 11/180\n",
      "572/572 [==============================] - 149s 260ms/step - loss: 1.1981 - accuracy: 0.5030 - val_loss: 1.1537 - val_accuracy: 0.5024\n",
      "Epoch 12/180\n",
      "572/572 [==============================] - 145s 254ms/step - loss: 1.1164 - accuracy: 0.5104 - val_loss: 1.0804 - val_accuracy: 0.5437\n",
      "Epoch 13/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 1.0483 - accuracy: 0.5407 - val_loss: 1.0112 - val_accuracy: 0.5806\n",
      "Epoch 14/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.9836 - accuracy: 0.5968 - val_loss: 0.9691 - val_accuracy: 0.5879\n",
      "Epoch 15/180\n",
      "572/572 [==============================] - 157s 274ms/step - loss: 0.9371 - accuracy: 0.6247 - val_loss: 0.9171 - val_accuracy: 0.6390\n",
      "Epoch 16/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.9004 - accuracy: 0.6467 - val_loss: 0.8935 - val_accuracy: 0.6384\n",
      "Epoch 17/180\n",
      "572/572 [==============================] - 157s 274ms/step - loss: 0.8655 - accuracy: 0.6706 - val_loss: 0.8531 - val_accuracy: 0.6809\n",
      "Epoch 18/180\n",
      "572/572 [==============================] - 150s 263ms/step - loss: 0.8366 - accuracy: 0.6884 - val_loss: 0.8257 - val_accuracy: 0.6933\n",
      "Epoch 19/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.8069 - accuracy: 0.7107 - val_loss: 0.8058 - val_accuracy: 0.7064\n",
      "Epoch 20/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.7842 - accuracy: 0.7246 - val_loss: 0.8047 - val_accuracy: 0.7042\n",
      "Epoch 21/180\n",
      "572/572 [==============================] - 149s 260ms/step - loss: 0.7633 - accuracy: 0.7417 - val_loss: 0.7618 - val_accuracy: 0.7456\n",
      "Epoch 22/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.7444 - accuracy: 0.7538 - val_loss: 0.7534 - val_accuracy: 0.7407\n",
      "Epoch 23/180\n",
      "572/572 [==============================] - 157s 274ms/step - loss: 0.7238 - accuracy: 0.7665 - val_loss: 0.7354 - val_accuracy: 0.7554\n",
      "Epoch 24/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.7074 - accuracy: 0.7757 - val_loss: 0.7188 - val_accuracy: 0.7669\n",
      "Epoch 25/180\n",
      "572/572 [==============================] - 156s 273ms/step - loss: 0.6921 - accuracy: 0.7837 - val_loss: 0.7051 - val_accuracy: 0.7697\n",
      "Epoch 26/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.6781 - accuracy: 0.7926 - val_loss: 0.6974 - val_accuracy: 0.7788\n",
      "Epoch 27/180\n",
      "572/572 [==============================] - 148s 259ms/step - loss: 0.6607 - accuracy: 0.8036 - val_loss: 0.6873 - val_accuracy: 0.7838\n",
      "Epoch 28/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.6481 - accuracy: 0.8097 - val_loss: 0.6770 - val_accuracy: 0.7924\n",
      "Epoch 29/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 0.6377 - accuracy: 0.8138 - val_loss: 0.6708 - val_accuracy: 0.7920\n",
      "Epoch 30/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.6247 - accuracy: 0.8220 - val_loss: 0.6656 - val_accuracy: 0.7948\n",
      "Epoch 31/180\n",
      "572/572 [==============================] - 156s 273ms/step - loss: 0.6117 - accuracy: 0.8286 - val_loss: 0.6552 - val_accuracy: 0.8045\n",
      "Epoch 32/180\n",
      "572/572 [==============================] - 152s 266ms/step - loss: 0.6006 - accuracy: 0.8349 - val_loss: 0.6478 - val_accuracy: 0.8091\n",
      "Epoch 33/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.5905 - accuracy: 0.8397 - val_loss: 0.6472 - val_accuracy: 0.8028\n",
      "Epoch 34/180\n",
      "572/572 [==============================] - 153s 267ms/step - loss: 0.5777 - accuracy: 0.8475 - val_loss: 0.6441 - val_accuracy: 0.8108\n",
      "Epoch 35/180\n",
      "572/572 [==============================] - 153s 268ms/step - loss: 0.5681 - accuracy: 0.8510 - val_loss: 0.6448 - val_accuracy: 0.8110\n",
      "Epoch 36/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.5617 - accuracy: 0.8537 - val_loss: 0.6373 - val_accuracy: 0.8117\n",
      "Epoch 37/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.5492 - accuracy: 0.8599 - val_loss: 0.6282 - val_accuracy: 0.8168\n",
      "Epoch 38/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 0.5418 - accuracy: 0.8630 - val_loss: 0.6223 - val_accuracy: 0.8196\n",
      "Epoch 39/180\n",
      "572/572 [==============================] - 145s 253ms/step - loss: 0.5319 - accuracy: 0.8667 - val_loss: 0.6240 - val_accuracy: 0.8183\n",
      "Epoch 40/180\n",
      "572/572 [==============================] - 150s 262ms/step - loss: 0.5219 - accuracy: 0.8739 - val_loss: 0.6200 - val_accuracy: 0.8237\n",
      "Epoch 41/180\n",
      "572/572 [==============================] - 155s 270ms/step - loss: 0.5162 - accuracy: 0.8760 - val_loss: 0.6239 - val_accuracy: 0.8238\n",
      "Epoch 42/180\n",
      "572/572 [==============================] - 152s 266ms/step - loss: 0.5071 - accuracy: 0.8806 - val_loss: 0.6170 - val_accuracy: 0.8276\n",
      "Epoch 43/180\n",
      "572/572 [==============================] - 144s 253ms/step - loss: 0.5011 - accuracy: 0.8827 - val_loss: 0.6176 - val_accuracy: 0.8269\n",
      "Epoch 44/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.4926 - accuracy: 0.8848 - val_loss: 0.6170 - val_accuracy: 0.8263\n",
      "Epoch 45/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.4828 - accuracy: 0.8921 - val_loss: 0.6131 - val_accuracy: 0.8282\n",
      "Epoch 46/180\n",
      "572/572 [==============================] - 151s 265ms/step - loss: 0.4786 - accuracy: 0.8934 - val_loss: 0.6111 - val_accuracy: 0.8318\n",
      "Epoch 47/180\n",
      "572/572 [==============================] - 152s 265ms/step - loss: 0.4722 - accuracy: 0.8956 - val_loss: 0.6084 - val_accuracy: 0.8347\n",
      "Epoch 48/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.4641 - accuracy: 0.8983 - val_loss: 0.6209 - val_accuracy: 0.8251\n",
      "Epoch 49/180\n",
      "572/572 [==============================] - 144s 252ms/step - loss: 0.4572 - accuracy: 0.9026 - val_loss: 0.6143 - val_accuracy: 0.8329\n",
      "Epoch 50/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 141s 247ms/step - loss: 0.4488 - accuracy: 0.9065 - val_loss: 0.6300 - val_accuracy: 0.8248\n",
      "Epoch 51/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.4501 - accuracy: 0.9058 - val_loss: 0.6178 - val_accuracy: 0.8331\n",
      "Epoch 52/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.4416 - accuracy: 0.9093 - val_loss: 0.6194 - val_accuracy: 0.8294\n",
      "Epoch 53/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.4309 - accuracy: 0.9143 - val_loss: 0.6275 - val_accuracy: 0.8297\n",
      "Epoch 54/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4256 - accuracy: 0.9166 - val_loss: 0.6196 - val_accuracy: 0.8322\n",
      "Epoch 55/180\n",
      "572/572 [==============================] - 146s 256ms/step - loss: 0.4252 - accuracy: 0.9173 - val_loss: 0.6126 - val_accuracy: 0.8387\n",
      "Epoch 56/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4159 - accuracy: 0.9208 - val_loss: 0.6133 - val_accuracy: 0.8348\n",
      "Epoch 57/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.4093 - accuracy: 0.9238 - val_loss: 0.6198 - val_accuracy: 0.8341\n",
      "Epoch 58/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.4052 - accuracy: 0.9254 - val_loss: 0.6204 - val_accuracy: 0.8377\n",
      "Epoch 59/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.3975 - accuracy: 0.9291 - val_loss: 0.6222 - val_accuracy: 0.8355\n",
      "Epoch 60/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3964 - accuracy: 0.9298 - val_loss: 0.6337 - val_accuracy: 0.8364\n",
      "Epoch 61/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.3909 - accuracy: 0.9324 - val_loss: 0.6436 - val_accuracy: 0.8333\n",
      "Epoch 62/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3857 - accuracy: 0.9351 - val_loss: 0.6298 - val_accuracy: 0.8385\n",
      "Epoch 63/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.3828 - accuracy: 0.9347 - val_loss: 0.6331 - val_accuracy: 0.8381\n",
      "Epoch 64/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3758 - accuracy: 0.9376 - val_loss: 0.6316 - val_accuracy: 0.8419\n",
      "Epoch 65/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3720 - accuracy: 0.9402 - val_loss: 0.6398 - val_accuracy: 0.8357\n",
      "Epoch 66/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3670 - accuracy: 0.9426 - val_loss: 0.6456 - val_accuracy: 0.8351\n",
      "Epoch 67/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.3673 - accuracy: 0.9405 - val_loss: 0.6653 - val_accuracy: 0.8299\n",
      "Epoch 68/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3588 - accuracy: 0.9456 - val_loss: 0.6643 - val_accuracy: 0.8327\n",
      "Epoch 69/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.3589 - accuracy: 0.9455 - val_loss: 0.6368 - val_accuracy: 0.8396\n",
      "Epoch 70/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3556 - accuracy: 0.9449 - val_loss: 0.6600 - val_accuracy: 0.8354\n",
      "Epoch 71/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.3492 - accuracy: 0.9486 - val_loss: 0.6760 - val_accuracy: 0.8310\n",
      "Epoch 72/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3457 - accuracy: 0.9507 - val_loss: 0.6548 - val_accuracy: 0.8372\n",
      "Epoch 73/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3440 - accuracy: 0.9513 - val_loss: 0.6629 - val_accuracy: 0.8360\n",
      "Epoch 74/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3408 - accuracy: 0.9523 - val_loss: 0.6585 - val_accuracy: 0.8358\n",
      "Epoch 75/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.3374 - accuracy: 0.9528 - val_loss: 0.6570 - val_accuracy: 0.8377\n",
      "Epoch 76/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.3336 - accuracy: 0.9555 - val_loss: 0.6582 - val_accuracy: 0.8388\n",
      "Epoch 77/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3295 - accuracy: 0.9575 - val_loss: 0.6690 - val_accuracy: 0.8325\n",
      "Epoch 78/180\n",
      "572/572 [==============================] - 147s 257ms/step - loss: 0.3263 - accuracy: 0.9587 - val_loss: 0.6543 - val_accuracy: 0.8421\n",
      "Epoch 79/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3237 - accuracy: 0.9599 - val_loss: 0.6963 - val_accuracy: 0.8348\n",
      "Epoch 80/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.3218 - accuracy: 0.9615 - val_loss: 0.6678 - val_accuracy: 0.8364\n",
      "Epoch 81/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3194 - accuracy: 0.9610 - val_loss: 0.6718 - val_accuracy: 0.8394\n",
      "Epoch 82/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3161 - accuracy: 0.9615 - val_loss: 0.6629 - val_accuracy: 0.8386\n",
      "Epoch 83/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3141 - accuracy: 0.9627 - val_loss: 0.6638 - val_accuracy: 0.8410\n",
      "Epoch 84/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3081 - accuracy: 0.9656 - val_loss: 0.6755 - val_accuracy: 0.8389\n",
      "Epoch 85/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.3105 - accuracy: 0.9635 - val_loss: 0.6734 - val_accuracy: 0.8395\n",
      "Epoch 86/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.3066 - accuracy: 0.9660 - val_loss: 0.6701 - val_accuracy: 0.8407\n",
      "Epoch 87/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.3018 - accuracy: 0.9688 - val_loss: 0.6824 - val_accuracy: 0.8417\n",
      "Epoch 88/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2989 - accuracy: 0.9692 - val_loss: 0.6877 - val_accuracy: 0.8402\n",
      "Epoch 89/180\n",
      "572/572 [==============================] - 154s 269ms/step - loss: 0.3009 - accuracy: 0.9667 - val_loss: 0.6729 - val_accuracy: 0.8432\n",
      "Epoch 90/180\n",
      "572/572 [==============================] - 139s 242ms/step - loss: 0.2976 - accuracy: 0.9682 - val_loss: 0.6883 - val_accuracy: 0.8423\n",
      "Epoch 91/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.2955 - accuracy: 0.9694 - val_loss: 0.6859 - val_accuracy: 0.8392\n",
      "Epoch 92/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2946 - accuracy: 0.9701 - val_loss: 0.6999 - val_accuracy: 0.8387\n",
      "Epoch 93/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2927 - accuracy: 0.9708 - val_loss: 0.7022 - val_accuracy: 0.8379\n",
      "Epoch 94/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2919 - accuracy: 0.9700 - val_loss: 0.6853 - val_accuracy: 0.8406\n",
      "Epoch 95/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.2889 - accuracy: 0.9718 - val_loss: 0.7029 - val_accuracy: 0.8382\n",
      "Epoch 96/180\n",
      "572/572 [==============================] - 151s 264ms/step - loss: 0.2865 - accuracy: 0.9722 - val_loss: 0.6766 - val_accuracy: 0.8433\n",
      "Epoch 97/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2827 - accuracy: 0.9748 - val_loss: 0.6874 - val_accuracy: 0.8406\n",
      "Epoch 98/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2851 - accuracy: 0.9732 - val_loss: 0.7080 - val_accuracy: 0.8385\n",
      "Epoch 99/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2796 - accuracy: 0.9753 - val_loss: 0.7048 - val_accuracy: 0.8392\n",
      "Epoch 100/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2807 - accuracy: 0.9736 - val_loss: 0.6947 - val_accuracy: 0.8397\n",
      "Epoch 101/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2781 - accuracy: 0.9754 - val_loss: 0.6916 - val_accuracy: 0.8413\n",
      "Epoch 102/180\n",
      "572/572 [==============================] - 152s 265ms/step - loss: 0.2773 - accuracy: 0.9748 - val_loss: 0.6890 - val_accuracy: 0.8444\n",
      "Epoch 103/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.2756 - accuracy: 0.9752 - val_loss: 0.7112 - val_accuracy: 0.8352\n",
      "Epoch 104/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2765 - accuracy: 0.9752 - val_loss: 0.6963 - val_accuracy: 0.8423\n",
      "Epoch 105/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 143s 249ms/step - loss: 0.2717 - accuracy: 0.9775 - val_loss: 0.7040 - val_accuracy: 0.8390\n",
      "Epoch 106/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2709 - accuracy: 0.9768 - val_loss: 0.7178 - val_accuracy: 0.8334\n",
      "Epoch 107/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2678 - accuracy: 0.9783 - val_loss: 0.6993 - val_accuracy: 0.8432\n",
      "Epoch 108/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2669 - accuracy: 0.9785 - val_loss: 0.7016 - val_accuracy: 0.8434\n",
      "Epoch 109/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2668 - accuracy: 0.9786 - val_loss: 0.7135 - val_accuracy: 0.8418\n",
      "Epoch 110/180\n",
      "572/572 [==============================] - 138s 242ms/step - loss: 0.2663 - accuracy: 0.9790 - val_loss: 0.7000 - val_accuracy: 0.8424\n",
      "Epoch 111/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2636 - accuracy: 0.9791 - val_loss: 0.6943 - val_accuracy: 0.8441\n",
      "Epoch 112/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2623 - accuracy: 0.9802 - val_loss: 0.7076 - val_accuracy: 0.8409\n",
      "Epoch 113/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2612 - accuracy: 0.9803 - val_loss: 0.7220 - val_accuracy: 0.8372\n",
      "Epoch 114/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2608 - accuracy: 0.9799 - val_loss: 0.7373 - val_accuracy: 0.8339\n",
      "Epoch 115/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2618 - accuracy: 0.9800 - val_loss: 0.7215 - val_accuracy: 0.8375\n",
      "Epoch 116/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2588 - accuracy: 0.9802 - val_loss: 0.7026 - val_accuracy: 0.8420\n",
      "Epoch 117/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2553 - accuracy: 0.9821 - val_loss: 0.7068 - val_accuracy: 0.8404\n",
      "Epoch 118/180\n",
      "572/572 [==============================] - 139s 244ms/step - loss: 0.2528 - accuracy: 0.9832 - val_loss: 0.7157 - val_accuracy: 0.8424\n",
      "Epoch 119/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2534 - accuracy: 0.9824 - val_loss: 0.7062 - val_accuracy: 0.8421\n",
      "Epoch 120/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2536 - accuracy: 0.9824 - val_loss: 0.7132 - val_accuracy: 0.8410\n",
      "Epoch 121/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2502 - accuracy: 0.9837 - val_loss: 0.7071 - val_accuracy: 0.8405\n",
      "Epoch 122/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2513 - accuracy: 0.9826 - val_loss: 0.7123 - val_accuracy: 0.8414\n",
      "Epoch 123/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2506 - accuracy: 0.9827 - val_loss: 0.7103 - val_accuracy: 0.8432\n",
      "Epoch 124/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2490 - accuracy: 0.9828 - val_loss: 0.7056 - val_accuracy: 0.8413\n",
      "Epoch 125/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2477 - accuracy: 0.9838 - val_loss: 0.7098 - val_accuracy: 0.8410\n",
      "Epoch 126/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2481 - accuracy: 0.9833 - val_loss: 0.7095 - val_accuracy: 0.8408\n",
      "Epoch 127/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.2459 - accuracy: 0.9838 - val_loss: 0.7181 - val_accuracy: 0.8404\n",
      "Epoch 128/180\n",
      "572/572 [==============================] - 139s 244ms/step - loss: 0.2478 - accuracy: 0.9826 - val_loss: 0.7129 - val_accuracy: 0.8421\n",
      "Epoch 129/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2425 - accuracy: 0.9853 - val_loss: 0.6969 - val_accuracy: 0.8435\n",
      "Epoch 130/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2431 - accuracy: 0.9843 - val_loss: 0.7149 - val_accuracy: 0.8410\n",
      "Epoch 131/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2436 - accuracy: 0.9837 - val_loss: 0.7130 - val_accuracy: 0.8422\n",
      "Epoch 132/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2405 - accuracy: 0.9852 - val_loss: 0.7267 - val_accuracy: 0.8388\n",
      "Epoch 133/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2416 - accuracy: 0.9847 - val_loss: 0.7034 - val_accuracy: 0.8436\n",
      "Epoch 134/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2395 - accuracy: 0.9856 - val_loss: 0.7051 - val_accuracy: 0.8426\n",
      "Epoch 135/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.2379 - accuracy: 0.9869 - val_loss: 0.7071 - val_accuracy: 0.8424\n",
      "Epoch 136/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2388 - accuracy: 0.9856 - val_loss: 0.7059 - val_accuracy: 0.8451\n",
      "Epoch 137/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2374 - accuracy: 0.9852 - val_loss: 0.7254 - val_accuracy: 0.8404\n",
      "Epoch 138/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2362 - accuracy: 0.9860 - val_loss: 0.7141 - val_accuracy: 0.8454\n",
      "Epoch 139/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2347 - accuracy: 0.9862 - val_loss: 0.7294 - val_accuracy: 0.8403\n",
      "Epoch 140/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2335 - accuracy: 0.9872 - val_loss: 0.7085 - val_accuracy: 0.8420\n",
      "Epoch 141/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2343 - accuracy: 0.9861 - val_loss: 0.7073 - val_accuracy: 0.8451\n",
      "Epoch 142/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2329 - accuracy: 0.9865 - val_loss: 0.7170 - val_accuracy: 0.8415\n",
      "Epoch 143/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2290 - accuracy: 0.9880 - val_loss: 0.7191 - val_accuracy: 0.8402\n",
      "Epoch 144/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2309 - accuracy: 0.9873 - val_loss: 0.7177 - val_accuracy: 0.8439\n",
      "Epoch 145/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2309 - accuracy: 0.9870 - val_loss: 0.7263 - val_accuracy: 0.8390\n",
      "Epoch 146/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2296 - accuracy: 0.9871 - val_loss: 0.7363 - val_accuracy: 0.8415\n",
      "Epoch 147/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2290 - accuracy: 0.9875 - val_loss: 0.7044 - val_accuracy: 0.8416\n",
      "Epoch 148/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2288 - accuracy: 0.9876 - val_loss: 0.7295 - val_accuracy: 0.8387\n",
      "Epoch 149/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2279 - accuracy: 0.9872 - val_loss: 0.7330 - val_accuracy: 0.8360\n",
      "Epoch 150/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2285 - accuracy: 0.9868 - val_loss: 0.7189 - val_accuracy: 0.8386\n",
      "Epoch 151/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2266 - accuracy: 0.9877 - val_loss: 0.7005 - val_accuracy: 0.8431\n",
      "Epoch 152/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2248 - accuracy: 0.9882 - val_loss: 0.7060 - val_accuracy: 0.8421\n",
      "Epoch 153/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2254 - accuracy: 0.9878 - val_loss: 0.7042 - val_accuracy: 0.8447\n",
      "Epoch 154/180\n",
      "572/572 [==============================] - 140s 246ms/step - loss: 0.2254 - accuracy: 0.9870 - val_loss: 0.7046 - val_accuracy: 0.8411\n",
      "Epoch 155/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2220 - accuracy: 0.9893 - val_loss: 0.7028 - val_accuracy: 0.8417\n",
      "Epoch 156/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2232 - accuracy: 0.9877 - val_loss: 0.7169 - val_accuracy: 0.8411\n",
      "Epoch 157/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2187 - accuracy: 0.9899 - val_loss: 0.7096 - val_accuracy: 0.8423\n",
      "Epoch 158/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2205 - accuracy: 0.9893 - val_loss: 0.6991 - val_accuracy: 0.8426\n",
      "Epoch 159/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2190 - accuracy: 0.9903 - val_loss: 0.7057 - val_accuracy: 0.8433\n",
      "Epoch 160/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2198 - accuracy: 0.9887 - val_loss: 0.6964 - val_accuracy: 0.8448\n",
      "Epoch 161/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2186 - accuracy: 0.9896 - val_loss: 0.7100 - val_accuracy: 0.8417\n",
      "Epoch 162/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2186 - accuracy: 0.9890 - val_loss: 0.7224 - val_accuracy: 0.8402\n",
      "Epoch 163/180\n",
      "572/572 [==============================] - 146s 255ms/step - loss: 0.2168 - accuracy: 0.9895 - val_loss: 0.7028 - val_accuracy: 0.8462\n",
      "Epoch 164/180\n",
      "572/572 [==============================] - 140s 245ms/step - loss: 0.2157 - accuracy: 0.9898 - val_loss: 0.7260 - val_accuracy: 0.8365\n",
      "Epoch 165/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2157 - accuracy: 0.9898 - val_loss: 0.7052 - val_accuracy: 0.8459\n",
      "Epoch 166/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2163 - accuracy: 0.9892 - val_loss: 0.7155 - val_accuracy: 0.8409\n",
      "Epoch 167/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2152 - accuracy: 0.9897 - val_loss: 0.6953 - val_accuracy: 0.8443\n",
      "Epoch 168/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2143 - accuracy: 0.9897 - val_loss: 0.7014 - val_accuracy: 0.8440\n",
      "Epoch 169/180\n",
      "572/572 [==============================] - 142s 249ms/step - loss: 0.2132 - accuracy: 0.9901 - val_loss: 0.7051 - val_accuracy: 0.8431\n",
      "Epoch 170/180\n",
      "572/572 [==============================] - 139s 243ms/step - loss: 0.2138 - accuracy: 0.9900 - val_loss: 0.7313 - val_accuracy: 0.8344\n",
      "Epoch 171/180\n",
      "572/572 [==============================] - 144s 251ms/step - loss: 0.2119 - accuracy: 0.9904 - val_loss: 0.6973 - val_accuracy: 0.8450\n",
      "Epoch 172/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2122 - accuracy: 0.9899 - val_loss: 0.7036 - val_accuracy: 0.8423\n",
      "Epoch 173/180\n",
      "572/572 [==============================] - 143s 251ms/step - loss: 0.2110 - accuracy: 0.9905 - val_loss: 0.7076 - val_accuracy: 0.8412\n",
      "Epoch 174/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2110 - accuracy: 0.9897 - val_loss: 0.6981 - val_accuracy: 0.8402\n",
      "Epoch 175/180\n",
      "572/572 [==============================] - 142s 248ms/step - loss: 0.2079 - accuracy: 0.9913 - val_loss: 0.6954 - val_accuracy: 0.8434\n",
      "Epoch 176/180\n",
      "572/572 [==============================] - 141s 247ms/step - loss: 0.2083 - accuracy: 0.9913 - val_loss: 0.6968 - val_accuracy: 0.8439\n",
      "Epoch 177/180\n",
      "572/572 [==============================] - 143s 250ms/step - loss: 0.2084 - accuracy: 0.9909 - val_loss: 0.6868 - val_accuracy: 0.8431\n",
      "Epoch 178/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2087 - accuracy: 0.9905 - val_loss: 0.7035 - val_accuracy: 0.8429\n",
      "Epoch 179/180\n",
      "572/572 [==============================] - 143s 249ms/step - loss: 0.2055 - accuracy: 0.9917 - val_loss: 0.7156 - val_accuracy: 0.8396\n",
      "Epoch 180/180\n",
      "572/572 [==============================] - 141s 246ms/step - loss: 0.2062 - accuracy: 0.9910 - val_loss: 0.6863 - val_accuracy: 0.8451\n",
      "Model name: model_0.8462_f7abf\n",
      "0.8462\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "{'loss': [6.840389425516128, 4.82163420176506, 3.5479988724589346, 2.7934876422286035, 2.333162705183029, 2.0098351671993733, 1.7633754370212555, 1.5717669932842255, 1.4225519049167632, 1.2993430709242821, 1.1980835683345794, 1.1163617692887784, 1.048317440122366, 0.9835642772465945, 0.9372025029659271, 0.9003716307133436, 0.8655302505791187, 0.8365926390588283, 0.8069149367660284, 0.784070046827197, 0.7631535654515028, 0.7442698941975832, 0.7236924821287394, 0.7073545029461383, 0.6922296018004418, 0.6780227932035923, 0.6606231214106083, 0.6481728565245867, 0.6377879158854485, 0.6246812552958727, 0.6115512457340956, 0.6005244696140289, 0.5905739942714572, 0.5776324874386192, 0.568269042365253, 0.5617980390340089, 0.5491450975313783, 0.5416394632905722, 0.532002921871841, 0.521861985437572, 0.5162136921137571, 0.506951729349792, 0.5010582676976919, 0.49256241776794196, 0.4827896469831467, 0.4786657025739551, 0.4722034969329834, 0.4640704062655568, 0.45727487517893317, 0.4488896024301648, 0.4498609063178301, 0.44152941308915616, 0.4309108802676201, 0.42570366813242433, 0.42512942119687797, 0.41584744314849376, 0.40928305219858885, 0.40503785863518715, 0.3974196120426059, 0.3963869398981333, 0.3909564315751195, 0.38574434826523063, 0.38285684818029403, 0.375857900261879, 0.3720587539076805, 0.3671206089705229, 0.36727597077935936, 0.35883665416389704, 0.35882287096232174, 0.3555770700201392, 0.3492495612949133, 0.3456235077530146, 0.343963344193995, 0.3408148608803749, 0.33732630920410156, 0.3336647259220481, 0.32954068830981853, 0.3263592132255435, 0.32377401618659496, 0.321809571351856, 0.319227215770632, 0.31608926724642517, 0.31417206466943026, 0.30810049816593527, 0.3104293180182576, 0.30655671570450066, 0.3018520962446928, 0.29892613431066273, 0.3009474535882473, 0.2976207541972399, 0.2954901311099529, 0.29467810796201227, 0.2926675635576248, 0.29194751058146357, 0.2887321418337524, 0.2864385106638074, 0.2827332771606743, 0.2851462199650705, 0.2796285650618374, 0.280720924410969, 0.27812093278765676, 0.2773611372821033, 0.27561159086972475, 0.2763845448307693, 0.27170517851412296, 0.2709635353125632, 0.2677484442405403, 0.26688316463679074, 0.2667830146960914, 0.26627281528711316, 0.2635723723322153, 0.2622634007707238, 0.26117942441627384, 0.2608079519383609, 0.2617703595198691, 0.25882321849837897, 0.2552843460589647, 0.25280039709433916, 0.2534115786775947, 0.2535726146027446, 0.2502509693019092, 0.2512838436067104, 0.25058064591139556, 0.2490090121217072, 0.24768591667711734, 0.24817899303883315, 0.24589488561451436, 0.2477101032137871, 0.2424973927140236, 0.2430991959348321, 0.24358711460977792, 0.24047106264531612, 0.2416118281520903, 0.23954010504484177, 0.23789339819923044, 0.23885108729451895, 0.23735017292201518, 0.236269123185426, 0.23467361821234226, 0.23348411120846868, 0.23426689925789834, 0.23291129684448242, 0.22903941559419036, 0.23092032236233354, 0.2308644246608019, 0.22966153378784657, 0.22897738268598913, 0.22872840449213983, 0.22791158140078188, 0.22848421795293689, 0.22643729212507605, 0.22484948182478548, 0.22532476575672628, 0.2253863883279264, 0.2220161117389798, 0.22318266935646533, 0.21872007271274924, 0.22056671930477023, 0.21884059800952674, 0.21979593600705266, 0.21863838488981127, 0.2185588279142976, 0.21677400993183255, 0.21565697441622614, 0.21566759994998574, 0.21634075213968754, 0.21525662310048937, 0.21432241467759014, 0.2131747118420899, 0.2137834666147828, 0.2119287962988019, 0.21222206756472586, 0.2109984554424882, 0.21107611963152886, 0.2078840143047273, 0.20835500785708427, 0.20845789132639767, 0.20870443142950534, 0.2054845032505691, 0.20623294176533818], 'accuracy': [0.504625, 0.503725, 0.50215, 0.503075, 0.499125, 0.499725, 0.5058, 0.504375, 0.5055, 0.503, 0.502975, 0.510425, 0.5407, 0.59685, 0.624675, 0.646675, 0.670625, 0.688375, 0.7107, 0.724575, 0.741725, 0.7538, 0.7665, 0.77575, 0.78375, 0.79265, 0.803625, 0.80965, 0.8138, 0.82205, 0.828625, 0.8349, 0.839725, 0.8475, 0.851025, 0.853675, 0.8599, 0.862975, 0.8667, 0.873875, 0.875975, 0.880575, 0.88265, 0.884825, 0.892125, 0.8934, 0.89555, 0.898325, 0.902625, 0.9065, 0.905775, 0.909275, 0.91435, 0.9166, 0.917325, 0.92085, 0.92385, 0.9254, 0.929075, 0.9298, 0.93245, 0.935075, 0.9347, 0.937625, 0.94015, 0.94255, 0.940525, 0.945625, 0.94545, 0.9449, 0.9486, 0.950725, 0.951275, 0.9523, 0.952825, 0.9555, 0.957475, 0.9587, 0.9599, 0.9615, 0.961, 0.961475, 0.96265, 0.965575, 0.9635, 0.96595, 0.968775, 0.96915, 0.966675, 0.96825, 0.96945, 0.9701, 0.970825, 0.97005, 0.97175, 0.9722, 0.9748, 0.97325, 0.975275, 0.9736, 0.975425, 0.97485, 0.9752, 0.975225, 0.9775, 0.97685, 0.978325, 0.978525, 0.9786, 0.978975, 0.979075, 0.980225, 0.980275, 0.979925, 0.980025, 0.9802, 0.98205, 0.983225, 0.9824, 0.982375, 0.98375, 0.98265, 0.98275, 0.982825, 0.983825, 0.983325, 0.9838, 0.98265, 0.9853, 0.98425, 0.983675, 0.9852, 0.98465, 0.985575, 0.98685, 0.985575, 0.98525, 0.986, 0.986225, 0.987225, 0.986075, 0.986525, 0.98795, 0.987275, 0.987, 0.987075, 0.9875, 0.987575, 0.9872, 0.98675, 0.98775, 0.988225, 0.9878, 0.98705, 0.989325, 0.9877, 0.989925, 0.98925, 0.9903, 0.98875, 0.9896, 0.98895, 0.989525, 0.9898, 0.9898, 0.9892, 0.989725, 0.989725, 0.9901, 0.990025, 0.9904, 0.989875, 0.99055, 0.9897, 0.991325, 0.99135, 0.99095, 0.990475, 0.991675, 0.991], 'val_loss': [5.704066139834744, 4.072621108768703, 3.10691784645294, 2.5283651652036014, 2.1559615018484477, 1.875696419002293, 1.6594134594177032, 1.4919717620302748, 1.356956551958631, 1.2453575901218228, 1.153703186895464, 1.0804314029800308, 1.011243865206525, 0.9691170291467146, 0.9171144778911884, 0.8934668423412563, 0.8530946961649648, 0.8256835637392698, 0.8057648447843698, 0.8047308871796081, 0.7618426122031845, 0.7533950413857307, 0.7354040796106512, 0.718820498956667, 0.7051439552040367, 0.6973700031533941, 0.6872604539344361, 0.6770243011154495, 0.6708123681845365, 0.6655774612526794, 0.6551686900478977, 0.647822322128536, 0.6471578733070747, 0.6440862160879415, 0.6448074529221007, 0.6373110576109453, 0.6282286362631337, 0.622345354173567, 0.6239535652257345, 0.6199886807194956, 0.6239070006600627, 0.6169600843132793, 0.6176151251876271, 0.6169641247162452, 0.6131031486121091, 0.6111075976095, 0.6083529351891338, 0.6208654781738361, 0.6142715790888646, 0.6300303364967133, 0.6177667318940996, 0.6193570123685823, 0.6274928448500333, 0.6196088519963351, 0.6125964724517369, 0.6133287292677205, 0.6198285595103578, 0.62041758115475, 0.6221883724202643, 0.633671552359641, 0.6436174059664452, 0.6298169614551784, 0.6330613106280774, 0.6315761971306968, 0.6398318728783747, 0.6455651757183608, 0.6653472443560621, 0.6643130112361241, 0.6368114971197568, 0.6599779329099855, 0.6760368292981928, 0.6548157922037832, 0.6628577725870626, 0.6585120881770874, 0.6569962778708318, 0.6581900419888796, 0.6689689995108784, 0.6543256711292934, 0.6962900382655484, 0.6678396079923723, 0.6717685331831446, 0.6628690182745873, 0.6637874408201738, 0.675507455022185, 0.6734126235221649, 0.6700927383832999, 0.682387465155208, 0.6876523555158736, 0.6728565490745998, 0.6882720279110062, 0.6859013213144316, 0.6998865289704783, 0.7022021181516714, 0.6853313248057465, 0.702852041988106, 0.6766161385116044, 0.6874193480381598, 0.7080440529576548, 0.7047849954008223, 0.6947269879437826, 0.6915729054204234, 0.6889955099229212, 0.7112380568380956, 0.6962645556126441, 0.7040056855111689, 0.7178012774540827, 0.6993001422265193, 0.7015518681569533, 0.7135094593871724, 0.6999675231380063, 0.6943305182707059, 0.7075779192097538, 0.7219663654174004, 0.7373441782864657, 0.7215242598440263, 0.7026213222033494, 0.7068411184774412, 0.7156561240032836, 0.7061791818041901, 0.7132109336919717, 0.7071284507954871, 0.7122775645522804, 0.710304524098243, 0.7055824313547228, 0.709783815212183, 0.7094726622938277, 0.7181070219803524, 0.7129293688527354, 0.6969334618611769, 0.7149352593855425, 0.7129888176084398, 0.7266570792331563, 0.703420793468302, 0.7051179996737234, 0.7071112275540412, 0.7059424004771493, 0.7253617029506844, 0.7140537929701638, 0.7293698156213427, 0.7085118214567224, 0.7073116110755013, 0.7169674634933472, 0.7190536012599519, 0.7176939011453749, 0.7262642444013716, 0.7362981688726199, 0.7043767146297268, 0.7295122544665437, 0.7330222713363754, 0.7188639434484335, 0.7004802472941525, 0.7059728767905202, 0.7041530398638932, 0.7045572141667346, 0.7027718977077858, 0.7168718709812297, 0.7095976767840085, 0.6991093129544825, 0.7057087754869794, 0.6963862789260757, 0.7099912218697422, 0.7223568452404929, 0.7028168971305127, 0.7259987357196275, 0.7052348741701433, 0.7155326636104317, 0.6953131835777443, 0.7013749182224274, 0.705065151819816, 0.7313325086256841, 0.6973145122711475, 0.7035929473130019, 0.7075805874554427, 0.6980709737831062, 0.6954163144101629, 0.6968039899439245, 0.6867721628892672, 0.7035087234490401, 0.7156107396512599, 0.6863389978042016], 'val_accuracy': [0.5007, 0.4989, 0.5016, 0.5011, 0.5011, 0.5011, 0.4993, 0.5011, 0.5011, 0.4989, 0.5024, 0.5437, 0.5806, 0.5879, 0.639, 0.6384, 0.6809, 0.6933, 0.7064, 0.7042, 0.7456, 0.7407, 0.7554, 0.7669, 0.7697, 0.7788, 0.7838, 0.7924, 0.792, 0.7948, 0.8045, 0.8091, 0.8028, 0.8108, 0.811, 0.8117, 0.8168, 0.8196, 0.8183, 0.8237, 0.8238, 0.8276, 0.8269, 0.8263, 0.8282, 0.8318, 0.8347, 0.8251, 0.8329, 0.8248, 0.8331, 0.8294, 0.8297, 0.8322, 0.8387, 0.8348, 0.8341, 0.8377, 0.8355, 0.8364, 0.8333, 0.8385, 0.8381, 0.8419, 0.8357, 0.8351, 0.8299, 0.8327, 0.8396, 0.8354, 0.831, 0.8372, 0.836, 0.8358, 0.8377, 0.8388, 0.8325, 0.8421, 0.8348, 0.8364, 0.8394, 0.8386, 0.841, 0.8389, 0.8395, 0.8407, 0.8417, 0.8402, 0.8432, 0.8423, 0.8392, 0.8387, 0.8379, 0.8406, 0.8382, 0.8433, 0.8406, 0.8385, 0.8392, 0.8397, 0.8413, 0.8444, 0.8352, 0.8423, 0.839, 0.8334, 0.8432, 0.8434, 0.8418, 0.8424, 0.8441, 0.8409, 0.8372, 0.8339, 0.8375, 0.842, 0.8404, 0.8424, 0.8421, 0.841, 0.8405, 0.8414, 0.8432, 0.8413, 0.841, 0.8408, 0.8404, 0.8421, 0.8435, 0.841, 0.8422, 0.8388, 0.8436, 0.8426, 0.8424, 0.8451, 0.8404, 0.8454, 0.8403, 0.842, 0.8451, 0.8415, 0.8402, 0.8439, 0.839, 0.8415, 0.8416, 0.8387, 0.836, 0.8386, 0.8431, 0.8421, 0.8447, 0.8411, 0.8417, 0.8411, 0.8423, 0.8426, 0.8433, 0.8448, 0.8417, 0.8402, 0.8462, 0.8365, 0.8459, 0.8409, 0.8443, 0.844, 0.8431, 0.8344, 0.845, 0.8423, 0.8412, 0.8402, 0.8434, 0.8439, 0.8431, 0.8429, 0.8396, 0.8451]}\n",
      "[0.6863412060937681, 0.8451]\n",
      "RESULT:\n",
      "{'loss': -0.8461999893188477, 'real_loss': 0.6863412060937681, 'best_val_loss': 0.6083529351891338, 'best_val_accuracy': 0.8461999893188477, 'model_name': 'model_0.8462_f7abf', 'space': {'activation': 'relu', 'batch_size': 70.0, 'conv_dropout_drop_proba': 0.2319040800996359, 'conv_hiddn_units_mult': 0.7004255447579512, 'conv_kernel_size': 3.0, 'conv_pool_res_start_idx': 2.0, 'epochs': 180.0, 'fc_dropout_drop_proba': 0.17590859742643258, 'fc_units_1_mult': 0.9697958299395057, 'first_conv': None, 'l2_weight_reg_mult': 3.3401336643592123, 'lr_rate_mult': 0.6582150163080535, 'nb_conv_pool_layers': 2, 'one_more_fc': 1.1848111467718283, 'optimizer': 'Adam', 'pooling_type': 'inception', 'res_conv_kernel_size': 3.0, 'residual': None, 'use_BN': True}, 'status': 'ok'}\n",
      "{\n",
      "    \"best_val_accuracy\": 0.8461999893188477,\n",
      "    \"best_val_loss\": 0.6083529351891338,\n",
      "    \"loss\": -0.8461999893188477,\n",
      "    \"model_name\": \"model_0.8462_f7abf\",\n",
      "    \"real_loss\": 0.6863412060937681,\n",
      "    \"space\": {\n",
      "        \"activation\": \"relu\",\n",
      "        \"batch_size\": 70.0,\n",
      "        \"conv_dropout_drop_proba\": 0.2319040800996359,\n",
      "        \"conv_hiddn_units_mult\": 0.7004255447579512,\n",
      "        \"conv_kernel_size\": 3.0,\n",
      "        \"conv_pool_res_start_idx\": 2.0,\n",
      "        \"epochs\": 180.0,\n",
      "        \"fc_dropout_drop_proba\": 0.17590859742643258,\n",
      "        \"fc_units_1_mult\": 0.9697958299395057,\n",
      "        \"first_conv\": null,\n",
      "        \"l2_weight_reg_mult\": 3.3401336643592123,\n",
      "        \"lr_rate_mult\": 0.6582150163080535,\n",
      "        \"nb_conv_pool_layers\": 2,\n",
      "        \"one_more_fc\": 1.1848111467718283,\n",
      "        \"optimizer\": \"Adam\",\n",
      "        \"pooling_type\": \"inception\",\n",
      "        \"res_conv_kernel_size\": 3.0,\n",
      "        \"residual\": null,\n",
      "        \"use_BN\": true\n",
      "    },\n",
      "    \"status\": \"ok\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model, model_name, results, log_path = build_and_train(\n",
    "        best_space_model,\n",
    "        save_best_weights=True,\n",
    "        log_for_tensorboard=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "_, test_it = h.construct_data_generator(batch_size=70, target_size=(128,128), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6863389978042016, 0.8451]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': -0.8461999893188477,\n",
       " 'real_loss': 0.6863412060937681,\n",
       " 'best_val_loss': 0.6083529351891338,\n",
       " 'best_val_accuracy': 0.8461999893188477,\n",
       " 'model_name': 'model_0.8462_f7abf',\n",
       " 'space': {'activation': 'relu',\n",
       "  'batch_size': 70.0,\n",
       "  'conv_dropout_drop_proba': 0.2319040800996359,\n",
       "  'conv_hiddn_units_mult': 0.7004255447579512,\n",
       "  'conv_kernel_size': 3.0,\n",
       "  'conv_pool_res_start_idx': 2.0,\n",
       "  'epochs': 180.0,\n",
       "  'fc_dropout_drop_proba': 0.17590859742643258,\n",
       "  'fc_units_1_mult': 0.9697958299395057,\n",
       "  'first_conv': None,\n",
       "  'l2_weight_reg_mult': 3.3401336643592123,\n",
       "  'lr_rate_mult': 0.6582150163080535,\n",
       "  'nb_conv_pool_layers': 2,\n",
       "  'one_more_fc': 1.1848111467718283,\n",
       "  'optimizer': 'Adam',\n",
       "  'pooling_type': 'inception',\n",
       "  'res_conv_kernel_size': 3.0,\n",
       "  'residual': None,\n",
       "  'use_BN': True},\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights/424d8.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7028168971305127, 0.8462]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = model.evaluate_generator(test_it)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "y_true = h.y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      4989\n",
      "           1       0.85      0.84      0.85      5011\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4229, 0.076 ],\n",
       "       [0.0778, 0.4233]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax= plt.subplot()\n",
    "sn.heatmap(confusion_matrix(y_true, y_pred), \n",
    "           annot=True, fmt='g', cmap=cm.RdBu_r, ax = ax, cbar=False)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['trigg 1', 'trigg 5']); ax.yaxis.set_ticklabels(['trigg 1', 'trigg 5']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
